{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706e896bca8245c2a89f3a3553dd1e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5279360b7c434b079f59d46fa7036dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcce47f6b244aa1b4ca9f3ba66e2c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8da22d1dda4da4ab2700b71d441e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot  Shirt  Bag  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6715, 0.9625, 0.8334, 0.4676, 0.7526, 0.4841, 0.3245, 0.3257, 0.7382,\n",
      "         0.2033],\n",
      "        [0.2348, 0.5416, 0.1491, 0.4923, 0.3643, 0.7566, 0.1390, 0.6434, 0.8630,\n",
      "         0.3871],\n",
      "        [0.2692, 0.9282, 0.2855, 0.3949, 0.9041, 0.6678, 0.0130, 0.0423, 0.5318,\n",
      "         0.6573],\n",
      "        [0.8723, 0.4350, 0.3012, 0.8002, 0.6124, 0.3487, 0.6848, 0.6387, 0.0223,\n",
      "         0.2736]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.1484954357147217\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            # tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.967653483211994\n",
      "  batch 2000 loss: 0.8668458288237453\n",
      "  batch 3000 loss: 0.6805671364376321\n",
      "  batch 4000 loss: 0.6325247878939845\n",
      "  batch 5000 loss: 0.5922179860165343\n",
      "  batch 6000 loss: 0.5397674814455676\n",
      "  batch 7000 loss: 0.5326238094862783\n",
      "  batch 8000 loss: 0.5106499622792471\n",
      "  batch 9000 loss: 0.4876671563899145\n",
      "  batch 10000 loss: 0.46399486570747106\n",
      "  batch 11000 loss: 0.4662110754119931\n",
      "  batch 12000 loss: 0.4453819991021883\n",
      "  batch 13000 loss: 0.435411801399976\n",
      "  batch 14000 loss: 0.43414435611490626\n",
      "  batch 15000 loss: 0.42425163701981367\n",
      "LOSS train 0.42425163701981367 valid 0.44744423031806946\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.4056588005162485\n",
      "  batch 2000 loss: 0.4091756519509363\n",
      "  batch 3000 loss: 0.4115357187232003\n",
      "  batch 4000 loss: 0.3979407914001786\n",
      "  batch 5000 loss: 0.38987503428017956\n",
      "  batch 6000 loss: 0.3694613380021765\n",
      "  batch 7000 loss: 0.3693110449571832\n",
      "  batch 8000 loss: 0.35505162596487205\n",
      "  batch 9000 loss: 0.38122188241954424\n",
      "  batch 10000 loss: 0.3683302572501707\n",
      "  batch 11000 loss: 0.39178204966432534\n",
      "  batch 12000 loss: 0.3466110673955991\n",
      "  batch 13000 loss: 0.3627079880336314\n",
      "  batch 14000 loss: 0.3240185681986841\n",
      "  batch 15000 loss: 0.33404739657491156\n",
      "LOSS train 0.33404739657491156 valid 0.36252561211586\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.32243947980663507\n",
      "  batch 2000 loss: 0.3281164889983902\n",
      "  batch 3000 loss: 0.3342453901445988\n",
      "  batch 4000 loss: 0.33319289467051205\n",
      "  batch 5000 loss: 0.32583984374103603\n",
      "  batch 6000 loss: 0.3196897236365185\n",
      "  batch 7000 loss: 0.3202591037485108\n",
      "  batch 8000 loss: 0.3211730858090814\n",
      "  batch 9000 loss: 0.3244484134049562\n",
      "  batch 10000 loss: 0.3346590429143398\n",
      "  batch 11000 loss: 0.313296149312926\n",
      "  batch 12000 loss: 0.3237832774586095\n",
      "  batch 13000 loss: 0.30691879803078337\n",
      "  batch 14000 loss: 0.33367636343667983\n",
      "  batch 15000 loss: 0.30338699154078497\n",
      "LOSS train 0.30338699154078497 valid 0.35120731592178345\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.31013756883966564\n",
      "  batch 2000 loss: 0.2910484676157721\n",
      "  batch 3000 loss: 0.2881446124622562\n",
      "  batch 4000 loss: 0.2892818356468233\n",
      "  batch 5000 loss: 0.3222150669882176\n",
      "  batch 6000 loss: 0.2798053721817851\n",
      "  batch 7000 loss: 0.29113356193540674\n",
      "  batch 8000 loss: 0.29060965643710734\n",
      "  batch 9000 loss: 0.27807717250256975\n",
      "  batch 10000 loss: 0.2952293189047923\n",
      "  batch 11000 loss: 0.30104917781994844\n",
      "  batch 12000 loss: 0.29113181761230955\n",
      "  batch 13000 loss: 0.2946458998079179\n",
      "  batch 14000 loss: 0.29171082607266724\n",
      "  batch 15000 loss: 0.2991544073656769\n",
      "LOSS train 0.2991544073656769 valid 0.3128315806388855\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.27638546741498793\n",
      "  batch 2000 loss: 0.2750407765641139\n",
      "  batch 3000 loss: 0.26827218050720514\n",
      "  batch 4000 loss: 0.2810648973710522\n",
      "  batch 5000 loss: 0.28845166865447025\n",
      "  batch 6000 loss: 0.2878741807880506\n",
      "  batch 7000 loss: 0.29141672983988653\n",
      "  batch 8000 loss: 0.2660318135128273\n",
      "  batch 9000 loss: 0.2761523042746194\n",
      "  batch 10000 loss: 0.27730502633826837\n",
      "  batch 11000 loss: 0.25534589564204724\n",
      "  batch 12000 loss: 0.27875831367407955\n",
      "  batch 13000 loss: 0.2654843905855632\n",
      "  batch 14000 loss: 0.2676896780796424\n",
      "  batch 15000 loss: 0.25902212374626654\n",
      "LOSS train 0.25902212374626654 valid 0.3399042785167694\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    # writer.add_scalars('Training vs. Validation Loss',\n",
    "    #                 { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "    #                 epoch_number + 1)\n",
    "    # writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
