{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import  pickle\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, mode = \"train\", max_sequence_length=128):\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        if mode == \"train\":\n",
    "            with open(\"./train.txt\", \"r\") as f:\n",
    "                self.datalist = f.readlines()\n",
    "        elif mode == \"test\":\n",
    "            with open(\"./test.txt\", \"r\") as f:\n",
    "                self.datalist = f.readlines()\n",
    "        text_tmp = open(\"data.json\")\n",
    "        data = json.load(text_tmp)\n",
    "        ann = {\"假\": 0, \"真\": 1, \"辟谣\": 2}\n",
    "        self.label_dict = {}\n",
    "        for i in data:\n",
    "            self.label_dict[i[\"video_id\"]] = ann[i[\"annotation\"]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imf = open('/mnt/c/Users/IT/Downloads/all/ptvgg19_frames/'+self.datalist[idx].strip()+'.pkl', 'rb')\n",
    "        data_imf = pickle.load(imf)\n",
    "        vf = h5py.File('/mnt/c/Users/IT/Downloads/all/c3d/'+self.datalist[idx].strip()+'.hdf5', 'r')\n",
    "        data_vf = vf[self.datalist[idx].strip()][\"c3d_features\"][:]\n",
    "        af = open('/mnt/c/Users/IT/Downloads/all/audiosconvfea/'+self.datalist[idx].strip(), 'rb')\n",
    "        data_af = pickle.load(af)\n",
    "        label = self.label_dict[self.datalist[idx].strip()]\n",
    "\n",
    "        data_imf = self.pad_or_truncate_sequence(data_imf)\n",
    "        data_vf = self.pad_or_truncate_sequence(data_vf)\n",
    "        data_af = self.pad_or_truncate_sequence(data_af)\n",
    "\n",
    "        return data_imf, data_vf, data_af, label\n",
    "    \n",
    "\n",
    "    def pad_or_truncate_sequence(self, sequence):\n",
    "        # 将 NumPy 数组转换为 PyTorch 张量\n",
    "        sequence = torch.from_numpy(sequence)\n",
    "\n",
    "        # 填充或截断序列，使其具有相同的长度\n",
    "        if len(sequence) < self.max_sequence_length:\n",
    "            # 填充\n",
    "            padding = torch.zeros((self.max_sequence_length - len(sequence), sequence.shape[1]))\n",
    "            sequence = torch.cat((sequence, padding))\n",
    "        elif len(sequence) > self.max_sequence_length:\n",
    "            # 截断\n",
    "            sequence = sequence[:self.max_sequence_length, :]\n",
    "\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CustomImageDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imf, data_vf, data_af, label = c[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 4096]), torch.Size([128, 4096]), torch.Size([128, 12288]))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imf.shape, data_vf.shape, data_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputI_size = 4096\n",
    "inputV_size = 4096\n",
    "inputA_size = 12288\n",
    "hidden_size = 128\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(128,128)\n",
    "b = torch.randn(128,128)\n",
    "c = torch.randn(128,128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 384])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.cat([a, b, c], dim=1)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = nn.ReLU(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, inputI_size, inputV_size, inputA_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc_imf = nn.Linear(inputI_size, hidden_size) \n",
    "        self.fc_vf = nn.Linear(inputV_size, hidden_size)  \n",
    "        self.fc_af = nn.Linear(inputA_size, hidden_size)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_fusion = nn.Linear(hidden_size * 3, output_size)  \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x_imf, x_vf, x_af):\n",
    "        x_imf = self.fc_imf(x_imf)\n",
    "        x_vf = self.fc_vf(x_vf)\n",
    "        x_af = self.fc_af(x_af)\n",
    "        # 将三种特征连接在一起\n",
    "        fused_features = torch.cat([x_imf, x_vf, x_af], dim=1)\n",
    "\n",
    "        # 对融合后的特征进行全连接\n",
    "        fused_features = self.relu(fused_features)\n",
    "        fused_features = self.fc_fusion(fused_features)\n",
    "        fused_features = self.softmax(fused_features)\n",
    "\n",
    "        return fused_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model = NeuralNetwork(inputI_size, inputV_size, inputA_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CustomImageDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CustomImageDataset(mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch 是一个包含多个样本的列表，每个样本是一个元组 (data_imf, data_vf, data_af, label)\n",
    "    imfs, vfs, afs, labels = zip(*batch)\n",
    "\n",
    "    # 使用 pad_sequence 进行填充\n",
    "    padded_imfs = rnn_utils.pad_sequence(imfs, batch_first=True)\n",
    "    padded_vfs = rnn_utils.pad_sequence(vfs, batch_first=True)\n",
    "    padded_afs = rnn_utils.pad_sequence(afs, batch_first=True)\n",
    "\n",
    "    # 返回填充后的数据和标签\n",
    "    return padded_imfs, padded_vfs, padded_afs, torch.tensor(labels)\n",
    "\n",
    "# 创建 DataLoader 时指定 collate_fn\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(test, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # batch 是一个包含多个样本的列表，每个样本是一个元组 (data_imf, data_vf, data_af, label)\n",
    "    imfs, vfs, afs, labels = zip(*batch)\n",
    "\n",
    "    # 使用 pad_sequence 进行填充\n",
    "    padded_imfs = rnn_utils.pad_sequence(imfs, batch_first=True)\n",
    "    padded_vfs = rnn_utils.pad_sequence(vfs, batch_first=True)\n",
    "    padded_afs = rnn_utils.pad_sequence(afs, batch_first=True)\n",
    "\n",
    "    # 直接将填充后的数据转换为 PyTorch 张量\n",
    "    padded_imfs = torch.tensor(padded_imfs)\n",
    "    padded_vfs = torch.tensor(padded_vfs)\n",
    "    padded_afs = torch.tensor(padded_afs)\n",
    "\n",
    "    # 返回填充后的数据和标签\n",
    "    return padded_imfs, padded_vfs, padded_afs, torch.tensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train, batch_size=4, shuffle=True),\n",
    "    'val': torch.utils.data.DataLoader(test, batch_size=4, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders = {'train': torch.utils.data.DataLoader(train, batch_size=4,\n",
    "#                                              shuffle=True),\n",
    "# 'val': torch.utils.data.DataLoader(test, batch_size=4,\n",
    "#                                              shuffle=True)\n",
    "#                                              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4256, -0.3148, -1.3210,  ...,  0.0560, -0.7306, -0.8196],\n",
       "         [-0.7379, -0.2910, -1.5157,  ...,  0.0189, -0.6578, -0.9554],\n",
       "         [-0.5325, -0.2531, -1.5586,  ...,  0.1187, -0.7828, -0.8430],\n",
       "         ...,\n",
       "         [-0.1492,  1.0484, -0.1234,  ..., -0.2936, -0.3012, -0.2957],\n",
       "         [-0.1312,  1.0226, -0.1796,  ..., -0.2905, -0.3724, -0.2205],\n",
       "         [-0.2015,  1.0845, -0.2335,  ..., -0.2483, -0.2853, -0.2584]]),\n",
       " tensor([[0.0000, 0.0000, 2.5520,  ..., 0.0000, 0.0000, 3.3453],\n",
       "         [0.0000, 0.0000, 4.0873,  ..., 0.0000, 0.0000, 2.2750],\n",
       "         [0.0000, 0.0000, 5.3454,  ..., 0.0000, 0.0000, 2.3237],\n",
       "         ...,\n",
       "         [0.0000, 0.5312, 0.5379,  ..., 0.0000, 0.0000, 1.7034],\n",
       "         [0.3185, 0.0000, 3.3585,  ..., 0.0000, 0.0000, 3.0217],\n",
       "         [0.8294, 0.0000, 3.8933,  ..., 0.0000, 0.0000, 2.8031]]),\n",
       " tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0371, 0.0000, 0.0000],\n",
       "         [0.0955, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.2634, 0.0531, 0.0000,  ..., 0.1340, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0430, 0.0000, 0.0000],\n",
       "         [0.0068, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 1)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.3602, -0.4651, -0.3777,  ...,  0.0718, -0.2641, -0.6900],\n",
      "         [-0.1122, -0.7719, -0.6257,  ..., -0.0328, -0.2836, -0.8467],\n",
      "         [-0.1533, -0.7232, -0.5291,  ...,  0.0277, -0.4541, -0.9145],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.6466, -0.2027, -1.9240,  ...,  0.2948, -0.5452, -1.2570],\n",
      "         [-0.0830,  0.4102, -1.4344,  ...,  0.1057,  0.0891, -0.7472],\n",
      "         [ 0.0260,  0.2577, -1.5819,  ...,  0.1294, -0.0723, -0.6357],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-2.0768, -0.9201, -4.0298,  ..., -1.4944, -1.4145, -5.2806],\n",
      "         [-2.1723, -1.0488, -3.9071,  ..., -0.9716, -2.1924, -5.8825],\n",
      "         [-1.7483, -0.4201, -4.3023,  ..., -0.7652, -2.5946, -5.7656],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-2.1706, -1.0132, -1.7080,  ..., -0.2210, -0.7519, -2.0328],\n",
      "         [-2.1236, -1.0145, -1.7305,  ..., -0.1611, -0.7606, -2.0326],\n",
      "         [-2.1782, -1.0393, -1.7068,  ..., -0.1719, -0.8027, -2.0226],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), tensor([[[2.8706e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.5060e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.6334e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 6.9523e-03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[1.2024e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [3.8996e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 5.8478e-01],\n",
      "         [1.9005e+00, 0.0000e+00, 1.3766e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 1.7830e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 8.2949e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 9.9575e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 8.2094e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]]), tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0759, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0139, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0734, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.1117, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0013, 0.0000, 0.0000,  ..., 0.0121, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]), tensor([1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "for b in dataloaders[\"train\"]:\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\"train\":len(train), \"val\": len(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        \n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputsV, inputsI, inputsA, labels in dataloaders[phase]:\n",
    "                    inputsV = inputsV.to(device)\n",
    "                    inputsV = inputsI.to(device)\n",
    "                    inputsA = inputsA.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputsV, inputsV, inputsA)\n",
    "                        # _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputsV.size(0)\n",
    "                    # running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4256, -0.3148, -1.3210,  ...,  0.0560, -0.7306, -0.8196],\n",
       "        [-0.7379, -0.2910, -1.5157,  ...,  0.0189, -0.6578, -0.9554],\n",
       "        [-0.5325, -0.2531, -1.5586,  ...,  0.1187, -0.7828, -0.8430],\n",
       "        ...,\n",
       "        [-0.1492,  1.0484, -0.1234,  ..., -0.2936, -0.3012, -0.2957],\n",
       "        [-0.1312,  1.0226, -0.1796,  ..., -0.2905, -0.3724, -0.2205],\n",
       "        [-0.2015,  1.0845, -0.2335,  ..., -0.2483, -0.2853, -0.2584]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = NeuralNetwork(inputI_size, inputV_size, inputA_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_ft(test[0][0], test[0][1], test[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4067, 0.2947, 0.2987],\n",
       "        [0.3824, 0.3153, 0.3023],\n",
       "        [0.3447, 0.4089, 0.2464],\n",
       "        [0.3649, 0.3973, 0.2379],\n",
       "        [0.4001, 0.3518, 0.2481],\n",
       "        [0.4032, 0.3639, 0.2329],\n",
       "        [0.4607, 0.2985, 0.2409],\n",
       "        [0.4375, 0.3102, 0.2522],\n",
       "        [0.4275, 0.3249, 0.2477],\n",
       "        [0.3536, 0.3699, 0.2765],\n",
       "        [0.3801, 0.3766, 0.2433],\n",
       "        [0.3875, 0.3615, 0.2510],\n",
       "        [0.4193, 0.3383, 0.2424],\n",
       "        [0.3767, 0.3446, 0.2787],\n",
       "        [0.3829, 0.3868, 0.2303],\n",
       "        [0.3158, 0.4291, 0.2551],\n",
       "        [0.3612, 0.3992, 0.2395],\n",
       "        [0.3716, 0.3651, 0.2632],\n",
       "        [0.4054, 0.3650, 0.2296],\n",
       "        [0.3884, 0.3681, 0.2435],\n",
       "        [0.3440, 0.4138, 0.2422],\n",
       "        [0.3900, 0.3423, 0.2677],\n",
       "        [0.3636, 0.3692, 0.2672],\n",
       "        [0.3417, 0.3981, 0.2603],\n",
       "        [0.4241, 0.3318, 0.2441],\n",
       "        [0.4572, 0.3386, 0.2042],\n",
       "        [0.4581, 0.3435, 0.1983],\n",
       "        [0.4391, 0.3213, 0.2396],\n",
       "        [0.3755, 0.3819, 0.2426],\n",
       "        [0.3726, 0.3847, 0.2427],\n",
       "        [0.3630, 0.3747, 0.2622],\n",
       "        [0.3572, 0.3919, 0.2509],\n",
       "        [0.3117, 0.4208, 0.2675],\n",
       "        [0.3264, 0.4113, 0.2623],\n",
       "        [0.3579, 0.3821, 0.2600],\n",
       "        [0.3434, 0.3834, 0.2732],\n",
       "        [0.3523, 0.3744, 0.2733],\n",
       "        [0.3555, 0.4079, 0.2366],\n",
       "        [0.3912, 0.3717, 0.2370],\n",
       "        [0.3994, 0.3434, 0.2572],\n",
       "        [0.4037, 0.3452, 0.2511],\n",
       "        [0.3961, 0.3344, 0.2695],\n",
       "        [0.4419, 0.3254, 0.2327],\n",
       "        [0.4501, 0.3301, 0.2198],\n",
       "        [0.4230, 0.3573, 0.2196],\n",
       "        [0.4455, 0.3318, 0.2227],\n",
       "        [0.3776, 0.3337, 0.2887],\n",
       "        [0.3845, 0.3258, 0.2898],\n",
       "        [0.4243, 0.3414, 0.2343],\n",
       "        [0.4395, 0.3273, 0.2333],\n",
       "        [0.3967, 0.3707, 0.2326],\n",
       "        [0.4214, 0.3556, 0.2230],\n",
       "        [0.4467, 0.3235, 0.2298],\n",
       "        [0.3948, 0.3597, 0.2455],\n",
       "        [0.3544, 0.3900, 0.2556],\n",
       "        [0.3566, 0.4178, 0.2255],\n",
       "        [0.3411, 0.4040, 0.2549],\n",
       "        [0.3548, 0.3870, 0.2581],\n",
       "        [0.3896, 0.3708, 0.2396],\n",
       "        [0.4187, 0.3233, 0.2580],\n",
       "        [0.3824, 0.3620, 0.2557],\n",
       "        [0.3577, 0.3513, 0.2910],\n",
       "        [0.3682, 0.3462, 0.2857],\n",
       "        [0.3712, 0.3654, 0.2634],\n",
       "        [0.4101, 0.3243, 0.2657],\n",
       "        [0.3997, 0.3632, 0.2371],\n",
       "        [0.3870, 0.3316, 0.2814],\n",
       "        [0.3605, 0.3281, 0.3114],\n",
       "        [0.3968, 0.3374, 0.2658],\n",
       "        [0.3766, 0.3651, 0.2583],\n",
       "        [0.4158, 0.3410, 0.2433],\n",
       "        [0.4349, 0.2975, 0.2675],\n",
       "        [0.4475, 0.3305, 0.2220],\n",
       "        [0.3559, 0.4179, 0.2262],\n",
       "        [0.3596, 0.3866, 0.2537],\n",
       "        [0.3614, 0.3918, 0.2468],\n",
       "        [0.3946, 0.3803, 0.2251],\n",
       "        [0.3667, 0.3937, 0.2396],\n",
       "        [0.3755, 0.3483, 0.2761],\n",
       "        [0.4167, 0.3658, 0.2175],\n",
       "        [0.3489, 0.3537, 0.2974],\n",
       "        [0.3563, 0.3571, 0.2867],\n",
       "        [0.3457, 0.3643, 0.2900],\n",
       "        [0.4146, 0.3438, 0.2416],\n",
       "        [0.3685, 0.3509, 0.2805],\n",
       "        [0.3929, 0.3394, 0.2677],\n",
       "        [0.3763, 0.3438, 0.2799],\n",
       "        [0.4080, 0.3280, 0.2640],\n",
       "        [0.4698, 0.2800, 0.2502],\n",
       "        [0.3560, 0.3747, 0.2693],\n",
       "        [0.4299, 0.3420, 0.2280],\n",
       "        [0.4239, 0.3458, 0.2304],\n",
       "        [0.4459, 0.3330, 0.2212],\n",
       "        [0.4077, 0.3326, 0.2597],\n",
       "        [0.3790, 0.3766, 0.2444],\n",
       "        [0.3482, 0.4313, 0.2204],\n",
       "        [0.3494, 0.4059, 0.2446],\n",
       "        [0.3673, 0.4144, 0.2182],\n",
       "        [0.3942, 0.3806, 0.2252],\n",
       "        [0.4246, 0.3351, 0.2403],\n",
       "        [0.4338, 0.3223, 0.2439],\n",
       "        [0.3520, 0.3880, 0.2600],\n",
       "        [0.3914, 0.3506, 0.2579],\n",
       "        [0.3265, 0.4018, 0.2717],\n",
       "        [0.3997, 0.3523, 0.2479],\n",
       "        [0.3775, 0.3809, 0.2416],\n",
       "        [0.3465, 0.3989, 0.2545],\n",
       "        [0.3439, 0.4090, 0.2471],\n",
       "        [0.3457, 0.4064, 0.2479],\n",
       "        [0.3429, 0.4074, 0.2497],\n",
       "        [0.3436, 0.4093, 0.2471],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224],\n",
       "        [0.3416, 0.3359, 0.3224]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1536x128 and 384x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[429], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[423], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# track history if only in train\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputsV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputsV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputsA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# _, preds = torch.max(outputs, 1)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[410], line 20\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x_imf, x_vf, x_af)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 对融合后的特征进行全连接\u001b[39;00m\n\u001b[1;32m     19\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(fused_features)\n\u001b[0;32m---> 20\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfused_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m fused_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(fused_features)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fused_features\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1536x128 and 384x3)"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21621627, 1.2825677 , 1.447454  , ..., 0.        , 1.7883198 ,\n",
       "        0.12972558],\n",
       "       [0.        , 1.1042053 , 0.47129965, ..., 0.        , 0.        ,\n",
       "        0.7814119 ],\n",
       "       [0.        , 0.00869048, 0.        , ..., 0.        , 0.        ,\n",
       "        1.7861747 ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 2.665276  , ..., 0.55926245, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 2.6870937 , ..., 0.95208526, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 2.6269674 , ..., 1.0240164 , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1647"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "keywords = []\n",
    "comments = []\n",
    "count = 0\n",
    "\n",
    "with open('./data_complete.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    keywords.append(data[i][\"keywords\"])\n",
    "    if data[i][\"comments\"]:\n",
    "        comments.append(data[i][\"comments\"])\n",
    "    if not data[i][\"comments\"]:\n",
    "        count = count + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3848"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "keywords = []\n",
    "comments = []\n",
    "count = 0\n",
    "\n",
    "with open('./data_complete.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    keywords.append(data[i][\"keywords\"])\n",
    "    if data[i][\"comments\"]:\n",
    "        comments.append(data[i][\"comments\"])\n",
    "#     if not data[i][\"comments\"]:\n",
    "#         count = count + 1\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100多颗恒星“离奇消失”是被外星人操控了',\n",
       " '100多颗恒星“离奇消失”是被外星人操控了',\n",
       " '100多颗恒星“离奇消失”是被外星人操控了',\n",
       " '100多颗恒星“离奇消失”是被外星人操控了',\n",
       " '100多颗恒星“离奇消失”是被外星人操控了',\n",
       " '119徐州化工厂爆炸',\n",
       " '119徐州化工厂爆炸',\n",
       " '119徐州化工厂爆炸',\n",
       " '120被堵路口致患者抢救无效死亡',\n",
       " '120被堵路口致患者抢救无效死亡',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '16名韩国护士因疫情严重辞职',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '19岁消防员救火时被坍塌的墙体压倒而牺牲',\n",
       " '2019年8月一架客机在黑龙江失事，42人遇难',\n",
       " '2019年8月一架客机在黑龙江失事，42人遇难',\n",
       " '2019年8月一架客机在黑龙江失事，42人遇难',\n",
       " '2019年8月一架客机在黑龙江失事，42人遇难',\n",
       " '2019年8月一架客机在黑龙江失事，42人遇难',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2019环邢台国际自行车赛连环大撞车',\n",
       " '2020东京奥运会开幕式烟花在富士山下提前燃放',\n",
       " '2020东京奥运会开幕式烟花在富士山下提前燃放',\n",
       " '2020东京奥运会开幕式烟花在富士山下提前燃放',\n",
       " '2020东京奥运会开幕式烟花在富士山下提前燃放',\n",
       " '2岁的孩子吃瓜子卡住喉咙，送到医院被延误治疗死亡',\n",
       " '2岁的孩子吃瓜子卡住喉咙，送到医院被延误治疗死亡',\n",
       " '2岁的孩子吃瓜子卡住喉咙，送到医院被延误治疗死亡',\n",
       " '2岁的孩子吃瓜子卡住喉咙，送到医院被延误治疗死亡',\n",
       " '2岁的孩子吃瓜子卡住喉咙，送到医院被延误治疗死亡',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '300元乘车卡免费送',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '35万元月薪招工建意大利方舱',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '36岁“女博士”征婚要求80万彩礼和别墅',\n",
       " '40年僵尸肉大量流入本地',\n",
       " '40年僵尸肉大量流入本地',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '5号线站内漏水',\n",
       " '60年来最冷冬天',\n",
       " '60年来最冷冬天',\n",
       " '60年来最冷冬天',\n",
       " '60年来最冷冬天',\n",
       " '60年来最冷冬天',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '6月15日起持有效签证和居留许可的外国人将无法入境',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '7月6日暴雨后，上海一公交车乘风破浪',\n",
       " '8岁白血病女孩为减轻父母负担自拔氧气管离世',\n",
       " '8岁白血病女孩为减轻父母负担自拔氧气管离世',\n",
       " '8岁白血病女孩为减轻父母负担自拔氧气管离世',\n",
       " '8岁白血病女孩为减轻父母负担自拔氧气管离世',\n",
       " '8岁白血病女孩为减轻父母负担自拔氧气管离世',\n",
       " '962899为服务老人的政府专线',\n",
       " '962899为服务老人的政府专线',\n",
       " '962899为服务老人的政府专线',\n",
       " '962899为服务老人的政府专线',\n",
       " '962899为服务老人的政府专线',\n",
       " '962899为服务老人的政府专线',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '99％樱桃都用膨大剂',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " '9人滞留湖北，吃光亲家三头猪',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'C罗送医,尤文图斯全队隔离',\n",
       " 'X大学向“国际学生”发放助学补贴半年',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“19岁逆行消防员背影”为烈士董泽鹏',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“哈佛八剑客”临危回国',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“掐指”手势能报警',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“水漫金山”在镇江上演',\n",
       " '“随手拍”举报交通违法奖励',\n",
       " '“随手拍”举报交通违法奖励',\n",
       " '“随手拍”举报交通违法奖励',\n",
       " '“随手拍”举报交通违法奖励',\n",
       " '“随手拍”举报交通违法奖励',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一儿童在浏阳北正西三楼钓鱼池内触电身亡',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一带一路从浙江义乌至英国伦敦的陆运火车',\n",
       " '一把粗盐一把口水破车窗玻璃',\n",
       " '一把粗盐一把口水破车窗玻璃',\n",
       " '一把粗盐一把口水破车窗玻璃',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一次违停收到两张罚单',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一男孩斑马线滑倒，后脑着地身亡',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '一颗白菜38.6元',\n",
       " '三亚大东海鲨鱼咬人',\n",
       " '三星堆纵目人后裔在四川剑阁',\n",
       " '上戏女学生携子闹场',\n",
       " '上戏女学生携子闹场',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海一乘客因未戴口罩被抬出地铁车厢',\n",
       " '上海南站停运消杀',\n",
       " '上海南站停运消杀',\n",
       " '上海南站停运消杀',\n",
       " '上海南站停运消杀',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海因垃圾分类发生命案',\n",
       " '上海地铁2号线爆炸',\n",
       " '上海地铁2号线爆炸',\n",
       " '上海地铁2号线爆炸',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海大宁公园有小孩落入结冰湖面',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海女大学生扶老人被诬陷',\n",
       " '上海建方舱医院',\n",
       " '上海建方舱医院',\n",
       " '上海建方舱医院',\n",
       " '上海建方舱医院',\n",
       " '上海建方舱医院',\n",
       " '上海建方舱医院',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海新冠确诊者电梯强吻',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海流浪汉毕业于复旦大学',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海浦东车管所暂停为特斯拉车上牌',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海海市蜃楼',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上海男子掏鸟窝踏空身亡',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '上饶广信区出现人贩子借清洗油烟机为名拐卖儿童',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '下雨天过横道线不可踏上斑马线的白漆面',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '不戴口罩驾车被扣6分',\n",
       " '世界上最有骨气的鱼，一言不合立马断气',\n",
       " '东山公园垮了',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞73岁大爷88万彩礼娶29岁妻子',\n",
       " '东莞大朗几名男女在大排档醉酒身亡',\n",
       " '东莞大朗几名男女在大排档醉酒身亡',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国84艘巨轮赴海湾抄底原油',\n",
       " '中国县长夫人在美国旅游，因饭菜不合口袭警被击毙',\n",
       " '中国县长夫人在美国旅游，因饭菜不合口袭警被击毙',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国大使向尼日利亚\"鞠躬道歉\"',\n",
       " '中国小伙在迪拜徒手赢得38公斤重金条',\n",
       " '中国小伙在迪拜徒手赢得38公斤重金条',\n",
       " '中国小伙在迪拜徒手赢得38公斤重金条',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国核潜发射全球打击的巨浪3型导弹',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国每年丢失儿童约20万仅有0.1%能找回',\n",
       " '中国科技城绵阳将进行2021元宵烟花预演',\n",
       " '中国科技城绵阳将进行2021元宵烟花预演',\n",
       " '中国科技城绵阳将进行2021元宵烟花预演',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国花100万美元买了加拿大龙卷风',\n",
       " '中国饮用水的质量相当于德国的处理污水',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '中秋微信红包有病毒',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临海或发生超历史性大洪水',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '临潼发生交通事故3人死亡',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为了应付无人机和卫星地图考核喷油漆',\n",
       " '为庆祝建国70周年，9月将补发养老金每人352元',\n",
       " '为庆祝建国70周年，9月将补发养老金每人352元',\n",
       " '为庆祝建国70周年，9月将补发养老金每人352元',\n",
       " '为放水追女神语文考零分',\n",
       " '为放水追女神语文考零分',\n",
       " '丽岙街道被大水淹没',\n",
       " '义乌三挺路台风天仍有夜市出摊',\n",
       " '义乌三挺路台风天仍有夜市出摊',\n",
       " '义乌三挺路台风天仍有夜市出摊',\n",
       " '乐山大佛变小鲜肉',\n",
       " '乐山大佛变小鲜肉',\n",
       " '乐山大佛变小鲜肉',\n",
       " '乐山大佛变小鲜肉',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山市一化工罐爆炸泄漏，产生大量烟雾',\n",
       " '乐山还要涨水宜宾菜坝被淹',\n",
       " '乐山还要涨水宜宾菜坝被淹',\n",
       " '乘客拍到无人机撞碎大客机侧翼',\n",
       " '乘客拍到无人机撞碎大客机侧翼',\n",
       " '乘客拍到无人机撞碎大客机侧翼',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟景区因泥石流临时关闭',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '九寨沟游客未买玉石被骂到抽搐',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '买支牙膏就能杀幽门螺杆菌',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '二战时期失踪的轰炸机停在月球上',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南一中学提供变质食物，食堂系县委书记岳父承包',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南勐海象群饮酒醉倒茶园',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '云南彝良棺材滑落致1死2伤',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '五角大楼公布的UFO视频是外星人存在的证据',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '京山孙桥发生一起交通事故造成4死2伤',\n",
       " '人民币停产',\n",
       " '人民币停产',\n",
       " '人民币停产',\n",
       " '人民币停产',\n",
       " '人民币停产',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年EB流感肆虐',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '今年元旦上海仅出生7个宝宝',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '仙居某公交停靠站发生欺凌事件',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗人站在山头上看阿塞拜疆和亚美尼亚两个国家打仗',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '伊朗核科学家遭暗杀车内视频曝光',\n",
       " '优衣库不雅视频女主角演出',\n",
       " '优衣库不雅视频女主角演出',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '体育馆小孩3岁被大狗把半边脸咬伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山一仓库起火致1人轻伤',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛山山火肆虐，浓烟直冲云霄',\n",
       " '佛罗里达洲的台风',\n",
       " '佛罗里达洲的台风',\n",
       " '佛罗里达洲的台风',\n",
       " '佛罗里达洲的台风',\n",
       " '佛罗里达洲的台风',\n",
       " '使用消毒液不要抽烟',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯小学生零下50度顶暴风雪回家',\n",
       " '俄罗斯航空展意大利飞行表演队发生意外',\n",
       " '俄罗斯航空展意大利飞行表演队发生意外',\n",
       " '俄罗斯航空展，意大利10架飞机相撞损毁',\n",
       " '俄罗斯航空展，意大利10架飞机相撞损毁',\n",
       " '俄罗斯航空展，意大利10架飞机相撞损毁',\n",
       " '保姆被打',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '修地铁的钢筋一“摔”即断“',\n",
       " '健康宝崩了进不了地铁',\n",
       " '健康宝崩了进不了地铁',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国31省市摘口罩时间表公布',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全国有七万硕士在送外卖',\n",
       " '全州县城关完小后门发生持刀砍人案件',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八宝粥里面装的海绵',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '八毛钱治好的病，深圳儿童医院竟然要10多万',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '公交司机昏迷前将车停稳，车上乘客无人打电话急救',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '六安一女子因彩礼跳井自杀',\n",
       " '兰天广场铜人被推倒',\n",
       " '兰天广场铜人被推倒',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市城关区新港城十字抓获一名“人贩子”',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '兰州市某工地塔吊倒塌，有人坠亡',\n",
       " '养宠物会导致流产、胎儿畸形',\n",
       " '养宠物会导致流产、胎儿畸形',\n",
       " '养宠物会导致流产、胎儿畸形',\n",
       " '养宠物会导致流产、胎儿畸形',\n",
       " '养宠物会导致流产、胎儿畸形',\n",
       " '内地女生在美国某火山口游玩坠落熔浆',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '内蒙古锡盟东乌旗发生地壳推移',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '出逃金钱豹被搜救犬下“死口”',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '刘海燕698分考入美国哈佛大学',\n",
       " '初中教师遭人肉自杀',\n",
       " '初中教师遭人肉自杀',\n",
       " '初中教师遭人肉自杀',\n",
       " '初中教师遭人肉自杀',\n",
       " '初中教师遭人肉自杀',\n",
       " '初中教师遭人肉自杀',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '副镇长视察灾情有专人撑伞',\n",
       " '加油时玩手机致汽车爆炸',\n",
       " '加油时玩手机致汽车爆炸',\n",
       " '加油时玩手机致汽车爆炸',\n",
       " '加油时玩手机致汽车爆炸',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地坛公园器械运动发生意外',\n",
       " '北京地铁为防疫情卸掉座椅',\n",
       " '北京地铁为防疫情卸掉座椅',\n",
       " '北京地铁为防疫情卸掉座椅',\n",
       " '北京地铁为防疫情卸掉座椅',\n",
       " '北京地铁为防疫情卸掉座椅',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京自来水加大氯气注入，需静置两小时以上再用',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北京西站出现大量白衣人，疑似疫情大爆发',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '北仑打麻将被要求抬桌子走10公里处罚',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '医生，我可不可以晚一点死啊，我不想妈妈哭',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '十堰火车站爆炸',\n",
       " '千余吨病死猪肉流入11省区',\n",
       " '千余吨病死猪肉流入11省区',\n",
       " '千余吨病死猪肉流入11省区',\n",
       " '千余吨病死猪肉流入11省区',\n",
       " '千余吨病死猪肉流入11省区',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华为北斗手机免费上网打电话',\n",
       " '华人李建军用无人机在美国放火烧山',\n",
       " '华人李建军用无人机在美国放火烧山',\n",
       " '华人李建军用无人机在美国放火烧山',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华山医院物资被盗',\n",
       " '华春莹:那些背叛祖国的明星禁止使用中国护照',\n",
       " '华春莹:那些背叛祖国的明星禁止使用中国护照',\n",
       " '华春莹:那些背叛祖国的明星禁止使用中国护照',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '华裔女孩在加拿大遭多人暴打',\n",
       " '南一路发生车祸现场孩子找妈妈',\n",
       " '南一路发生车祸现场孩子找妈妈',\n",
       " '南一路发生车祸现场孩子找妈妈',\n",
       " ...]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5495"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[503], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, keyword \u001b[38;5;129;01min\u001b[39;00m indexed_keywords:\n\u001b[1;32m     13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(keyword, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     last_hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     17\u001b[0m     feature \u001b[38;5;241m=\u001b[39m last_hidden_states  \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:286\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    278\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    285\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 286\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "model_name = './bert-base-chinese/'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "indexed_keywords = [(i, keywords) for i, group in enumerate(keywords) for comment in group]\n",
    "\n",
    "# 提取keywords特征\n",
    "features = []\n",
    "for i, keyword in indexed_keywords:\n",
    "    inputs = tokenizer(keyword, return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    feature = last_hidden_states  \n",
    "    features.append({\n",
    "        'index': data[i][\"video_id\"],\n",
    "        'input_ids': feature.flatten().detach().numpy()\n",
    "    })\n",
    "\n",
    "# 保存特征\n",
    "features_path = './text_keywords.pt'\n",
    "torch.save(features, features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1541,  0.4216, -0.7977,  ..., -0.0375, -0.2507,  0.3271],\n",
       "         [-0.5716,  0.1056,  0.2506,  ..., -0.4534, -0.0112,  0.2752],\n",
       "         [-0.0119, -0.1084, -0.3049,  ...,  0.2324,  0.8298, -0.3112],\n",
       "         ...,\n",
       "         [ 1.7274, -0.1018, -0.2066,  ...,  0.3424,  0.5099,  0.1122],\n",
       "         [ 0.7383,  0.4764,  0.0848,  ..., -0.6071, -0.7224, -0.3605],\n",
       "         [-0.1490, -0.0086,  0.2895,  ..., -0.1016,  0.0882, -0.0244]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.load('./text_comments.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1427, 1427,  784,  720, 8024, 2802, 1378, 4413, 3766, 4413,  749,\n",
       "          8024, 6375, 2769, 2897, 6814, 3341, 2496, 1378, 4413, 4500,  749, 8024,\n",
       "           671, 2661,  671,  724, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2772, 6387, 2769,  812, 6963, 3221, 3378,  702, 2342, 1920, 4495,\n",
       "          4289,  860, 1079, 4638, 2164, 4495, 6001, 5387,  749,  510,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3766,  752, 8024,  679, 2512, 1510, 2769, 6814, 2399, 2218, 6121,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2608, 3215, 1726, 2157, 6814, 2399, 1343,  749,  138, 2926, 5567,\n",
       "           140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1420, 4289, 4415, 5439, 2360, 6432, 2769,  812,  782, 5102, 3221,\n",
       "           124, 5335, 4958, 7313, 5507, 2137, 3300,  125, 5335, 4638, 3291, 7770,\n",
       "          5277, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1166, 4638, 3215, 4413, 4343, 5489, 6586, 1408, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1071, 2141,  782, 5102, 2347, 5307, 1762,  671,  702, 6428, 1277,\n",
       "          7027,  749, 8024, 6443, 6432, 3766, 3300, 3890, 2578, 3717, 3766, 3300,\n",
       "          3709, 3698, 4638, 1765, 3175,  679,  833, 2100, 1762, 4495, 1462, 8043,\n",
       "          1372, 3221,  782, 5102, 5632, 2346, 4638, 2137,  721, 5387,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6629, 1159, 8024, 3766, 3300,  782, 1762, 2692, 6821, 1767, 4135,\n",
       "          7410,  511, 6821, 1372,  679, 6814, 3221,  671, 1767, 2255, 4125, 8024,\n",
       "           671, 3613, 3197, 4135, 8024,  671,  702, 4289, 4905, 4638, 4127, 5318,\n",
       "          8024,  671, 2429, 1814, 2356, 4638, 3867, 1927, 8024, 4684, 1168, 6821,\n",
       "          1767, 4135, 7410, 1469, 3680,  702,  782, 2622, 2622, 4685, 1068,  100,\n",
       "           100,  517, 3837, 3857, 1765, 4413,  518,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2130,  749, 8024, 3221, 6662, 3791, 2458, 4708,  800, 4638, 7350,\n",
       "          3791, 3172, 1384, 8024, 3341, 1932, 1357, 1765, 4413, 5543, 3253,  749,\n",
       "           138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6963, 2571, 6814, 2399,  749, 8024, 5543, 6375, 2769,  812, 2128,\n",
       "          2552, 6814,  702, 1962, 2399, 1408, 8043,  138, 5010, 1526,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6435, 7309, 6821,  671,  752,  816, 2512, 1510, 2769, 1726, 2157,\n",
       "          6814, 2399,  679, 8043,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 7770, 5277, 3152, 3209, 2897, 6822, 2207, 2126, 2136,  704,\n",
       "          2458, 7023, 4289, 6574,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6821, 4958, 7313, 4638, 3198, 7313, 8024, 1469, 6929,  702, 4958,\n",
       "          7313, 4638, 3198, 7313,  679,  671, 3416, 8024,  738, 6387, 1765, 4413,\n",
       "          4638, 3198, 7313, 3683, 1166, 4638, 4958, 7313, 4638, 3198, 7313, 2714,\n",
       "          1450, 8024, 6574, 7030, 6632, 1920, 3198, 7313, 6632, 2571, 8024, 6574,\n",
       "          7030, 6632, 2207, 8024, 3198, 7313, 6632, 2571, 8024, 2772, 5442,  679,\n",
       "           671, 3416, 4638, 4958, 7313, 3198, 7313,  738,  679,  671, 3416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3221,  679, 3221, 6817, 1220, 1168,  749, 3378,  702,  782, 5102,\n",
       "          6225, 3844,  679, 1168, 4638, 1277, 1818,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 6230, 2533, 8024, 1922, 7345, 8024, 1765, 4413, 8024, 3299,\n",
       "           778, 8024, 7213, 3777, 5143, 8024, 7946, 3822, 8024, 2126, 2136, 8024,\n",
       "          6963, 3300, 5632, 2346, 4638, 2692, 6399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 6230, 2533, 2769, 4692,  749, 6821,  763, 8024, 2769, 2458,\n",
       "          1993, 2577, 4542,  782, 4495,  749,  138, 2926, 5567,  140,  138, 2926,\n",
       "          5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2533,  749, 1416, 8024, 6929, 7578, 3215, 4413, 1392, 4905, 1039,\n",
       "          5162, 6963, 3300, 8024, 6158, 2769, 3119, 6822, 2769, 4638, 3215, 6801,\n",
       "          2094, 2126, 2136,  976, 1906, 4500, 2141, 7741, 3215, 4413,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  138, 4263, 2552,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6821, 4905, 4385, 6496, 2400,  679, 5383, 6224, 8024, 2608, 3215,\n",
       "          4638, 1462, 6817, 2218, 3221, 6821, 3416, 1557, 8013, 6206,  720, 2218,\n",
       "          3221, 1359, 2768, 4635, 4765, 3215, 8024, 1107, 1316, 1359, 2768, 7946,\n",
       "          4765, 3215, 8024, 6206,  720, 2218, 3221, 1359, 2768, 7946, 3822, 8024,\n",
       "          1359, 2768, 6631, 3173, 3215, 6890, 6839,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  782, 5102, 3221, 1415, 6863, 1139,  749, 3683, 1726, 1765, 4413,\n",
       "          3291, 2571, 4638, 7607, 6121, 1690,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6432,  679, 2137, 1762, 6821, 8108, 2399, 4638, 3198, 7313, 8024,\n",
       "          6929,  763, 2608, 3215, 6963, 2347, 5307, 2100, 3833,  749, 1126, 4636,\n",
       "           674, 2399, 8024, 1372,  679, 6814, 3221, 4255, 4156, 3198, 7313, 3300,\n",
       "          4157, 2345, 6655, 5445, 2347,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 7270, 4761, 6399,  749, 8024,  138, 6614,  140,  138, 6614,  140,\n",
       "           138, 6614,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3241,  677, 4638, 3215, 3215, 1962, 4023,  778,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4906, 2110, 2157, 2418, 6421, 4777, 4955, 4777, 4955, 5632, 2346,\n",
       "          5632, 2346,  711,  784,  720, 3221,  782, 5102, 1450, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1266, 3353, 3215, 1348, 3221, 1525,  671, 7578, 2608, 3215, 1557,\n",
       "          8043,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2418, 6421, 3221, 6158, 3215, 1077, 1411, 7608,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769,  791, 2399, 1909, 1921, 2218, 4692, 6224,  671, 7578, 2523,\n",
       "           778, 4638, 3215, 3215, 4960, 4197, 3867, 1927,  749, 8024, 1157, 2848,\n",
       "          1928, 4692, 6224, 2124, 6230, 2533, 1962,  778, 8024, 4197, 1400,  671,\n",
       "           678, 2094, 2218, 3867, 1927,  749, 8024, 2769, 6820,  809,  711, 5632,\n",
       "          2346, 4692, 7231,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1567, 3221, 2382, 4415,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4906, 2110, 2157, 1355, 4385, 3221, 5635, 2208, 8135, 7578, 8024,\n",
       "          2769, 1355, 4385, 5635, 2208, 8238, 7578, 8024, 2769,  738,  679, 2345,\n",
       "          1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1765, 4413, 6963, 3766, 4777, 4955, 3209, 4635, 6820, 4777, 4955,\n",
       "          2126, 2136,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769,  812, 4692, 1168, 4638, 3215, 3215, 3313, 2553, 3221, 2608,\n",
       "          3215,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3215, 3215, 1726, 2157,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  782, 5303, 4955, 3221,  782, 8024, 2582,  720, 1377, 5543, 2968,\n",
       "          5164, 1139, 2126, 2136, 4638, 1952, 4908, 8024,  782, 5102, 4680, 1184,\n",
       "          4638, 1355, 4385, 8024, 6432,  679, 2137, 1372, 3221,  702, 5010, 6413,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1126, 1282, 2399, 1184, 2218, 3766,  749, 8024, 1372, 3221, 1157,\n",
       "          4692, 1168,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1346, 2162, 1724, 5050,  679, 5050,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3172, 5838,  762, 4413,  860,  138, 1960, 5010,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 7787,  794, 1765, 4413, 2810, 3141, 1168,  749, 2126, 2136,  138,\n",
       "          1920, 7965, 2096,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  782, 5102,  711, 3300, 4638, 7770, 2231, 4638, 2968, 5164, 2126,\n",
       "          2136, 8024, 2126, 2136, 4638, 3680, 4907, 4638, 2810, 2476, 6963, 3221,\n",
       "          3187, 3791, 2682, 6496, 4638, 8024, 1359, 1265, 3291, 3221, 2571, 1963,\n",
       "          4510, 8024, 3680,  671,  702, 1921,  860, 4638, 6121, 3215, 5102, 6963,\n",
       "          1762, 2810, 2476, 8024, 3300, 1962, 1914, 1962, 1914, 2399, 6768, 4638,\n",
       "          3215, 5143,  849, 1469, 2769,  812,  782, 5102, 4638, 2458, 1355, 1355,\n",
       "          2245, 2769,  812,  782, 5102, 4638, 3152, 1265, 8024, 2769, 6206, 2845,\n",
       "          1399, 8024,  711,  749,  782, 5102, 4638, 1920,  752,  689, 8024,  711,\n",
       "           749,  671,  702,  782, 5102, 7425, 1174, 1469, 2552, 4638,  752,  689,\n",
       "          8024,  138, 5010, 1526,  140,  138, 5010, 1526,  140,  138, 5010, 1526,\n",
       "           140,  138, 5010, 1526,  140,  138, 6614,  140,  138, 6614,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4906, 2110, 2157,  738, 3221,  782, 8024, 3221, 2769,  812,  782,\n",
       "          5102, 2300, 2876, 4638, 8024, 6237,  679, 2458, 4638, 1914,  749, 8024,\n",
       "          2126, 2136,  722, 1920, 8024,  782, 5102, 1372,  679, 6814, 3221, 1765,\n",
       "          4413, 6814, 2145, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094,  138, 5010, 1526,  140,  138, 5010, 1526,  140,  138,\n",
       "          5010, 1526,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6153, 1936,  138, 4857, 4876,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6432,  679, 2137, 2769,  812, 1762,  671,  702, 3313, 4761, 4638,\n",
       "           782,  671,  702, 6716,  677, 4638,  671,  702, 2207, 5301, 5528, 7027,\n",
       "          7481, 2218, 6825, 2126, 2136, 6963, 1762,  800, 6716,  860, 7027,  872,\n",
       "          6230, 2533, 1450,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 6432, 1921,  677, 3215, 3215, 2582,  720, 2208,  749, 6929,\n",
       "           720, 1914,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4919, 1220, 2458,  749, 1450,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 5314, 4788, 1776, 4868, 3926, 7370,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 7946, 3822, 3187, 7361, 4638, 2342, 1920, 1213, 7030, 3119,\n",
       "          1726, 1343,  749,  138, 4857, 4876,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3300, 7361, 4638, 1928, 5554, 3187, 3791,  749, 6237, 3187, 5296,\n",
       "          4638, 2126, 2136, 8024, 1372, 3300, 3143, 4519,  722, 2552, 8024, 5543,\n",
       "          2376, 1221, 2769,  812, 6371, 6399, 1158, 6863, 2126, 2136, 4638,  712,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 2126, 2136, 2342, 1077, 1391,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1765, 4413, 3221,  679, 3221, 6158, 1912, 3215,  782, 2458, 7023,\n",
       "          6814, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 7607, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  738, 6387, 1762, 1765, 4413, 4692,  677, 1343,  738, 2218, 1126,\n",
       "          1282, 2399, 8024, 6432,  679, 2137, 1762, 2126, 2136, 1166, 4638, 1765,\n",
       "          3175, 2347, 5307, 6814, 1343, 1126, 4636, 1126, 1283,  674, 2399,  749,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 2769, 2961, 1139,  860, 1912,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  738, 3300, 1377, 5543, 3300, 1369,  671,  702, 2126, 2136, 8024,\n",
       "          1429, 3119,  749, 6821, 7027, 4638, 3215, 4413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  138, 6614,  140,  138, 6614,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6963, 6158, 2769, 4159, 1265,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2990, 1184, 6842,  828,  749, 8024, 1726, 2157, 1075, 5439,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  678, 6777, 2094, 2769, 2496,  671, 7578, 7371, 4767,  138, 1960,\n",
       "          5010,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094,  138, 2926, 5567,  140,  138, 2926, 5567,  140,  138,\n",
       "          2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769,  812, 3418, 3315, 2218, 3766, 3300, 4696, 4638,  749, 6237,\n",
       "          6814, 2382, 4415, 4415, 6389, 6963, 3221,  782, 5102, 2682, 1139, 3341,\n",
       "          4638,  852, 2126, 2136, 4638, 2382, 4415, 4415, 6389, 4696, 4638, 1963,\n",
       "          2769,  812, 2682, 6496, 4638,  671, 3416, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2397,  784,  720, 8024, 2397,  784,  720, 8024,  679, 2218, 3221,\n",
       "          1914, 1391,  749, 1126, 7578, 5131, 1658,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1765, 4413, 3221, 3300,  924, 2844, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4906, 2110, 2157, 4638, 3300, 6395, 2945, 8024, 3766, 3300, 6395,\n",
       "          2945,  738, 2100, 1762, 4638, 1914,  749, 1343,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6825,  671,  702, 1045, 2094,  136,  679, 3221,  976, 3952, 2767,\n",
       "          4638, 1408, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1372, 6206,  782, 5102, 5543,  749, 6237, 3215, 4958,  704, 4638,\n",
       "          6821,  763, 4289, 6574, 2400, 5543, 2471, 4500, 1168, 5632, 6716, 8024,\n",
       "          6929,  782, 2218, 1377,  809, 2768, 4868, 8024, 4746, 7313, 2218, 1377,\n",
       "           809, 1168, 6809, 2682, 1343, 4638, 1765, 3175, 8024, 1259, 2886, 2126,\n",
       "          2136,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  872,  679, 4761, 6887, 3300, 1765,  677,  671, 1921, 1921,  677,\n",
       "           671, 2399, 4638, 6432, 3791, 1658, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2785, 3481, 4413, 8043, 1962, 1008, 1762, 5287, 5101, 3417, 2552,\n",
       "          7027, 7481, 1420, 6432, 6814,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2207, 1765, 4413, 8024,  872, 3221, 1415, 3300, 2523, 1914, 7309,\n",
       "          1384,  138, 1960, 5010,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2608, 3215, 8038, 2769, 5314, 7213, 3777, 6435,  969,  749, 8024,\n",
       "           679, 6121,  720,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 7770, 5277, 3152, 3209, 3021, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1922, 7345,  738,  833, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4385, 1762, 4638, 3215, 3215, 4696, 4638, 1962, 2208,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  872, 2582,  720, 4761, 6887, 6929,  763, 2608, 3215,  679, 3221,\n",
       "          2347, 5307, 2100, 1762,  749, 1126,  783, 2399, 8043, 3867, 1927, 3221,\n",
       "          1728,  711, 2347, 5307, 1168,  749, 4495, 1462, 4638, 2226, 1928,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1912, 3215,  782, 3696, 1744,  722, 4374, 1952, 4294, 3294,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4128, 3766, 4510,  749, 8024, 4127,  749, 8024, 1359, 2768, 4128,\n",
       "          3796,  749, 8024, 4692,  679, 1168,  749, 8024, 2218, 1008, 3766, 3300,\n",
       "          1045, 8024, 4706, 4714, 2218, 4692,  679, 1168,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1920, 6574, 7030, 2608, 3215, 2798, 5543, 3833, 1126, 4636,  674,\n",
       "          2399, 8043, 8043, 6929, 1922, 7345, 3221,  784,  720, 6574, 7030, 4638,\n",
       "          2608, 3215, 8043, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1071, 2141, 2769, 2218, 6421,  749,  702,  807, 4772,  138, 2926,\n",
       "          5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094, 8043, 8024, 1045, 2094, 2339,  868, 2147,  138, 1960,\n",
       "          5010,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  833,  679,  833, 2917, 7946, 3822, 1411, 1693,  749, 2769,  812,\n",
       "          1765, 4413,  833,  679,  833,  738, 2917,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6821, 3221, 2769, 1126, 1282, 2399, 1184, 3308, 1922, 7345, 1403,\n",
       "          2126, 2136, 2408, 3064,  749, 6929, 7578, 2608, 3215, 1777, 3403,  855,\n",
       "          5390, 4638, 5310, 3362,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2785, 3481, 4413, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6421, 2608, 3215, 1217, 6862, 6139, 4998,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  686, 4518, 3221, 5994, 3187, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  800, 6432,  749,  100, 1045, 2094,  100,  868, 5442, 4263, 4381,\n",
       "          1391, 7883, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769,  812, 1377, 5543,  738, 3221, 2523, 1914, 2126, 2136, 5299,\n",
       "          2768, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 2769, 3193, 2218, 4761, 6887, 2207, 3198,  952, 4692,\n",
       "          4638, 3215, 3215,  679,  671, 3416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6432, 3209, 2124,  934, 5298, 2768, 1216,  749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 1166, 4638, 6121, 3215, 3058, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1567, 3221, 1724, 5335, 4638, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2785, 3481, 4413, 6163, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2682, 4638, 6929,  720, 1908, 3325, 2397, 1658, 8043, 6821,  763,\n",
       "          3215, 4413, 1377, 5543, 2218, 3221, 5102,  849, 1922, 7345,  671, 3416,\n",
       "           833, 1355, 1045, 5445, 2347, 8024, 4197, 1400, 4234, 3160, 5450, 2226,\n",
       "          4173,  679, 6629, 3341, 2218, 4127,  749, 5445, 2347,  138, 5010, 1526,\n",
       "           140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 4638,  702, 1921, 1443, 8024, 4706, 4714, 3766, 3300,  679,\n",
       "          1922, 5709,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 4209, 2772, 3395, 4173, 2130,  749,  679, 2218, 1265, 2768, 4129,\n",
       "           749, 1408, 8024, 6821, 3300,  784,  720, 1936, 2597, 4638,  138, 2926,\n",
       "          5567,  140,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  809, 1184, 1762, 5439, 2157, 8024, 3241,  677, 1762, 1912, 7481,\n",
       "          4681, 4708, 1915, 4958, 4638,  671,  702, 3215, 3215, 4692, 8024, 4197,\n",
       "          1400, 4692, 4708, 4692, 4708, 6929, 7578, 3215, 4960, 4197, 7306, 4161,\n",
       "          1126,  678, 2218, 4127, 2957,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1377, 5543, 3221, 1343, 6943, 2233,  803, 1957, 1777, 1495, 1495,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  872,  679, 4761, 6887, 2126, 2136, 2212, 1812, 1408, 8043,  138,\n",
       "          2926, 5567,  140,  138, 2926, 5567,  140,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3215, 4413, 1920, 2773, 6783,  749, 8024, 6158, 1059, 4127,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 1420, 6224,  749, 1469, 2398, 5125, 5739,  113, 1045, 2094,\n",
       "           114,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 5610, 5515,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1420, 4289, 4415, 5439, 2360, 6432, 2769,  812,  782, 5102, 3221,\n",
       "           124, 5335, 4958, 7313, 5507, 2137, 3300,  125, 5335, 4638, 3291, 7770,\n",
       "          5277, 4638, 8013,  138, 5273, 5567, 6028,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2207, 3198,  952, 4638, 1909, 1921,  671, 1168, 3241,  677, 2218,\n",
       "          5543, 4692, 1168, 1962, 1914, 1962, 1914, 4638, 3215, 3215, 8024,  671,\n",
       "          7306,  671, 7306,  778, 3253, 3253,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6763,  816, 1399, 2099, 1373,  784,  720, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3300, 3766, 3300, 1377, 5543, 2769,  812, 6716,  860, 7027,  671,\n",
       "           833,  738, 3300,  671, 4905, 5299, 5302,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3300, 1068,  754, 6821,  671, 3175, 7481, 4638,  741, 1408, 8024,\n",
       "          2972, 5773,  671,  678,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 7309, 4788, 1776, 4868, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 7607, 5670, 3180, 6121, 7444, 6206, 5543, 3975, 8024, 7479, 2608,\n",
       "          3215, 5543, 3975,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2832, 5522,  749,  511,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  872, 2582,  720, 4761, 6887, 2124,  812, 6929,  763, 3215, 4413,\n",
       "           679, 3221, 1762, 1126, 4636,  674, 2399, 1184, 2218, 2347, 5307, 4495,\n",
       "          2768, 4638, 1450, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1726, 1343, 6814, 2399,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 6576, 1391, 6026, 1391, 4157,  749, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2608, 3215, 3221,  679, 3221, 2218, 3221,  671,  702, 4495, 1462,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3215, 4958, 2342, 1077, 1391, 2957,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6823, 1367, 7946, 3266, 1213, 7030,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([  101,   679,  1962,  2692,  2590,  8024,  5439,  1923,   680,   671,\n",
       "            855,  2370,  1862,  6887,  1351, 11659,  8024,   679,  2207,  2552,\n",
       "           1927,  2797,  2825,  5543,  3123,   974,  1045,   749,   138,  1960,\n",
       "           5010,   140,   102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3221,  679, 3221, 6963, 6158, 7392, 4895,  749, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1765, 4413, 1762, 2126, 2136,  704, 8024,  738, 3221, 4413, 3360,\n",
       "          7770, 2797, 8013,  138, 5010, 1526,  140,  138, 5010, 1526,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2785, 3481, 4413, 1139, 4385,  749,  100,  100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6432,  679, 2137, 7946, 3822, 7027, 7481, 3221, 1369,  671,  702,\n",
       "          2126, 2136,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 7027, 7481, 6963, 3221, 5543, 3975,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  137, 3634,  782, 3313, 6392, 5390, 3224, 4917, 9560,  113,  157,\n",
       "          8152, 8206, 8160, 8139, 8253, 8189, 8144, 8175, 8152, 8139, 8158, 8168,\n",
       "          8144, 8291,  114,  138, 1960, 5010,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2769, 2523, 1962, 1936, 6929,  763, 7946, 3822, 6963, 3221, 6858,\n",
       "          1403, 1525, 7027, 1435, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 3215,  756, 2582,  720, 4692, 1168,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3180, 3952, 1343,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094,  138, 5010, 1526,  140,  138, 5010, 1526,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094, 8043, 2769, 1962, 1008, 2682, 1168,  749,  784,  720,\n",
       "           138, 5010, 1526,  140,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 2418, 6421, 3221, 3300,  782, 1762, 6631, 6566, 5792, 2458, 1355,\n",
       "          2608, 3215, 5543, 7030,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1506, 1506, 6821,  720, 1914, 4263, 1962, 1921, 3152, 4761, 6399,\n",
       "          4638,  782, 1557,  138, 6614,  140,  138, 6614,  140,  138, 6614,  140,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6158, 7164, 7675, 1429, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1045, 2094, 8043, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  711,  784,  720,  833, 2682, 2768, 3867, 1927, 8024, 1377, 5543,\n",
       "          3221, 4919, 1220,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101,  738, 6387, 3193, 2218, 3766,  749, 8024, 1372, 3221, 1045, 6820,\n",
       "          1762,  837, 3064,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 1920, 3698, 2231, 3738, 3381,  698, 7028, 8024, 6387, 1914, 6121,\n",
       "          3215, 1139, 7305, 2785, 1366, 5388,  749, 8024, 2792,  809, 2864, 3029,\n",
       "          1139, 3341, 4692,  679, 1168, 8024, 2785,  749, 1366, 5388, 2582,  720,\n",
       "          1355, 1045,  138, 2926, 5567,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 3221, 3315, 2358, 3683, 7444, 6206, 2608, 3215, 4638, 5543, 7030,\n",
       "          3941, 1223,  138, 5010, 1526,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x4zj7hyemptkvm',\n",
       "  'input_ids': tensor([ 101, 6929,  872,  812, 6230, 2533, 1922, 7345, 1920, 6820, 3221, 2207,\n",
       "          3215, 3215, 1920, 1450, 8043, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101,  671, 4692, 1922, 4958,  671, 5102, 4638,  691, 6205, 2218, 2697,\n",
       "          6230,  782, 3833, 4708, 4696, 3766, 1567, 2692, 2590, 2218, 2496, 3615,\n",
       "          6605, 5401, 3250,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 1765, 4413, 3315, 2218, 3221, 1765, 1912, 3152, 3209, 4638, 7353,\n",
       "          2247, 1501, 8024, 7390,  872, 2582,  720, 2800, 5596,  738, 5436,  679,\n",
       "          1139, 1922, 7345, 5143,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 3159, 6760, 3215, 4919, 1557, 8013, 4919, 2458,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 3300,  671, 4905, 1921, 7987, 3215,  782,  683, 1391,  782, 5102,\n",
       "          8024, 1166, 2828,  800,  812, 1429, 2471, 3341, 2218, 1962,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 1372,  679, 6814, 1045,  679, 3221, 6825, 5330, 4638, 5445, 2347,\n",
       "          8024, 3300, 1567, 1920, 2661, 2207, 2597, 4638, 8024, 3291, 1068,  749,\n",
       "          4128, 1762, 2458,  679,  671, 3416, 1658, 8013, 1249,  754, 2590, 5440,\n",
       "          8024, 2190, 1920, 5554, 3300, 1962, 1905,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 7452, 7032, 3766, 6432,  711,  784,  720,  679, 1377,  809, 2970,\n",
       "          6239, 1912, 3215, 3152, 3209, 6890, 2742,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2218, 2586, 6814, 3341, 3119, 1922, 7345, 8024, 1963, 3362, 4696,\n",
       "          3341, 2582,  720, 1215, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 3119,  924, 2844, 6589,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2126, 2136,  704, 2553, 4197, 3300,  671, 4905, 4868, 4908, 4638,\n",
       "          1213, 7030,  712, 2153, 4708, 2126, 2136, 8024, 6158,  782,  812, 4917,\n",
       "           711,  677, 5721,  511, 2126, 2136,  704, 4638,  671, 1147, 4385, 6496,\n",
       "          1772,  711, 6134, 6496, 8024, 1963, 5712, 5709,  671, 4385,  511, 2218,\n",
       "          1008,  782,  671, 3416, 3341, 3187, 6679, 1343, 3187, 2512, 8024, 1372,\n",
       "           679, 6814, 3221, 4289, 6574, 6817, 1220, 4638, 1333, 2094, 2768, 1146,\n",
       "          4638, 5471, 3141,  511, 4397, 4263, 4495, 1462, 8024, 4397, 2667,  782,\n",
       "          4495,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 1921, 1557,  671, 4636, 1914, 3484, 2608, 3215, 3867, 1927,  872,\n",
       "          1501, 5301, 5301, 1501,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 3221, 5994, 2877, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2769, 3193, 2218, 6432, 6814, 8024, 2792, 6458, 1921, 4958, 3215,\n",
       "          3215, 8024, 6963, 3221, 1912, 3215, 3152, 3209, 4638, 2342, 1920, 7607,\n",
       "          4817, 8024, 4507, 3255, 2716, 4495, 1462, 3082, 2971, 8024, 1762, 6226,\n",
       "          1156, 5745, 1741, 1079, 3833, 1220, 8024, 1525, 1921, 1355, 4385,  679,\n",
       "          6224,  749, 8024, 6929, 2218, 3221, 6444, 1220, 2339,  868,  749,  511,\n",
       "          6821,  738, 6237, 7025,  749,  711,  784,  720, 6821,  763, 3215,  860,\n",
       "          5543, 1916, 7270, 3309, 2647, 3859, 1762, 4958,  704, 4638, 1333, 1728,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 3180, 6121, 5442,  671, 1384, 2218,  679, 2418, 6421, 2828, 1548,\n",
       "          4275, 2372,  677, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101,  782, 5102, 5303, 2199, 6845,  679, 6814, 4127,  767, 8024, 1912,\n",
       "          3215,  782,  738,  671, 3416, 1398, 1762, 2126, 2136,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 1912, 3215,  782, 1114, 1906, 7028, 3173, 3819, 4277,  749, 8024,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 6158, 2196, 1313,  749, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 3082, 2552, 6821,  720, 1914, 2397, 1658, 1450, 8043, 3300, 1391,\n",
       "          3300, 1600, 8024, 3300, 2339,  868, 8024, 2157,  782, 2398, 2128, 3683,\n",
       "           784, 7939, 6963, 1962, 8024, 2769, 3140, 6432, 1170, 1168, 6821,  702,\n",
       "          6228, 7574, 4638,  782, 3766, 3300,  671,  702, 5543, 2857, 6629, 2889,\n",
       "          3131, 1765, 4413, 4638, 6821,  702,  886, 1462, 8024, 2533, 6814,  684,\n",
       "          6814, 1416, 8024, 2571, 3833,  671, 1921, 3221,  671, 1921,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2769, 1762, 2682, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2347, 5307, 1139, 4385, 1693, 3215, 5442,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 1762, 6814,  671, 3667, 3198, 7313, 1765, 4413,  738, 1131, 4958,\n",
       "          3867, 1927,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 6656,  782,  671, 3416, 8024,  934, 2791, 2094, 8024, 2769,  812,\n",
       "          3221, 2905, 1765, 4413, 8024, 2124,  812, 3221, 2905, 3215,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2769,  812,  671, 4684, 6963, 1762, 1765, 4413, 8024,  872,  812,\n",
       "          6963,  679, 4761, 6887, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 6158, 7946, 3822, 1391,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 4127, 7464, 2828,  800,  812, 2519, 3302,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7041921581278416158',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 2212, 1812, 2913,  857,  749, 1416, 6821, 4905,  752,\n",
       "          2769, 6381, 2533,  809, 1184,  738, 3300, 6814, 1962, 1126, 3613,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2126, 2136, 6821,  720, 1920, 8024, 2769, 6825,  671, 7313, 2791,\n",
       "          2094, 6963, 4958, 7313, 6963, 3766, 3300,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 6929,  763,  686, 4518, 3274, 7463,  749, 5632, 2346, 4638,  855,\n",
       "          5390, 6158, 3926, 4415,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 6158, 2769, 4500, 3341, 5314, 7607, 5670, 6133, 1041, 5543, 7030,\n",
       "          4500, 2130,  749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 1372, 3221, 1776, 3647, 1126,  702, 5301, 5528, 5445, 2347,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 4692, 2130, 6963, 6230, 2533, 5632, 2346, 2418, 6421,\n",
       "          1343, 2496, 1921, 3152, 2110, 2157, 4777, 4955, 2126, 2136, 1762, 6821,\n",
       "          6820, 5709, 1446,  679, 3221, 2769, 6206, 4638, 4495, 3833,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 1728,  711, 6929, 6804, 3300,  782, 1762, 1548, 8038, 3036,  678,\n",
       "          3215, 3215, 5314,  872, 3036,  678, 3299,  778, 5314,  872,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 1920, 7481, 4916, 3647,  767, 4638, 6413, 8024, 6929, 2418, 6421,\n",
       "          2218, 3221, 6901, 4602,  749, 8024, 3683, 1963, 1094, 4307, 2608, 3215,\n",
       "          4567, 3681,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101,  794, 2607, 7987, 6822, 3341, 4638,  782, 2845, 6887,  671,  678,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101,  674,  671, 3221,  782, 2157, 3315, 3341, 2218, 1168,  749, 3314,\n",
       "          3309, 1450, 2769,  812, 4680, 1184, 4692, 1168, 4638, 3221, 1126,  674,\n",
       "          2399, 4493, 5635, 1126, 1282,  674, 2399, 1184, 4638, 2608, 3215, 4307,\n",
       "          2578, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2769,  812,  782, 5102, 1372, 3221, 2126, 2136, 4638, 3297,  856,\n",
       "          3152, 3209,  749, 1416, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2207, 3198,  952, 1921, 4958, 3215, 3215, 1962, 1914, 8024, 4385,\n",
       "          1762, 2523, 2208,  749, 8024, 5445,  684, 6963,  679,  778,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 1765, 4413,  677, 4638,  752, 2658, 6820, 3766, 2462, 3209, 4635,\n",
       "          8024, 6820, 4777, 4955, 2126, 2136,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2769, 3647, 3833, 2682,  679, 6858,  511, 3188, 4197, 1126, 4636,\n",
       "          1045, 2399, 1765, 3175, 6963, 5543, 4692, 2533, 6224, 8024,  711,  784,\n",
       "           720, 4692,  679, 1168,  800, 1765, 4413, 7027, 7481, 4638, 4495, 4289,\n",
       "          1450, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2207, 3198,  952, 1762,  740,  678, 8024, 3241,  677,  671, 2848,\n",
       "          1928, 3926, 3504, 4638, 4692, 6224, 4007, 1921, 3215, 8024, 4385, 1762,\n",
       "          1762, 1814, 7027, 3766, 4692, 6224, 6814,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 6158, 1912, 3215,  782, 2853, 2397,  749, 5543, 3975, 8024, 2608,\n",
       "          3215, 2218, 3867, 1927,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 6821, 3221,  671,  763, 6631, 5277, 1912, 3215, 3152, 3209, 1762,\n",
       "          2126, 2136, 3918, 4958,  704, 4255, 1355, 4638,  671, 1767, 2773,  751,\n",
       "          3673, 4127,  749, 2608, 3215,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 3215, 7354, 6837, 5661, 7027, 6381, 2533, 3300,  702, 1059, 5543,\n",
       "          4905, 3184,  159, 8024,  800,  812, 2802,  801, 2458,  671, 3366, 2218,\n",
       "          3221,  671,  702, 6631, 3173, 3215, 4255, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 3215, 3215, 1355, 1045, 3766, 1914,  719, 2218, 3867, 1927,  749,\n",
       "          1126, 1146, 7164, 1348, 1139, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2192, 3215, 1423, 4850,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 6929,  763, 2608, 3215, 3300, 1377, 5543, 6963, 6158, 7478, 2382,\n",
       "          7478, 2382, 1920, 6574, 7030, 4638, 7946, 3822, 5314, 1429, 6822, 1343,\n",
       "           749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2769,  711,  784,  720,  833, 4157, 6822, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 7213, 2335, 4638, 3215, 3215, 3291, 2208,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6853696307836488973',\n",
       "  'input_ids': tensor([ 101, 2769, 4692, 1168,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101,  679, 3221, 4638, 8024, 1728,  711, 7213, 3777, 5143, 1922, 7345,\n",
       "          5143, 4685, 2190,  855, 5390, 1359,  749, 8024, 3680,  702, 3215,  756,\n",
       "          6817, 1220, 6862, 2428,  679,  671, 3416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 7946, 3266, 3481, 3360, 2802, 1140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6158, 2769, 2897, 6624,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6929, 2218, 3221,  833, 2837, 1139,  511, 7471, 3862, 7220,  100,\n",
       "          4804, 8024, 4823, 3713, 3709, 3703, 3699,  511, 5287, 5401, 7199, 4795,\n",
       "          4840,  511,  511, 4800, 3714,  100, 7185, 7159,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6158, 1359, 2501, 7032, 1157, 3119, 1200,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101,  711,  784,  720,  833, 3867, 1927, 1450,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6158, 2769, 1391,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 1198, 4638, 2523, 3472, 3885, 4761, 6399,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6158, 3215, 4958, 2342, 1077, 1411, 2957,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6158, 7607, 4817, 2913,  857,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([  101,  1071,  2141,  3221,  5018,  1724,  2126,  8024,   711,   749,\n",
       "           3232,  1285,  1355,  1220,   749,  1057,   909,  2773,  8024,   679,\n",
       "            788,   788,  3221,  2608,  3215,  2208,   749,   511,  2523,  1914,\n",
       "           3215,  4413,  6963,  6158,  2802,  4255,   749,   511,   679,  6814,\n",
       "            679,  4500,  2857,  2552,   511,  4895,  2802,  1168, 12224,  8204,\n",
       "           3215,  1818,  1912,  1741,  6820,  2533,  1126,  1282,   674,  2399,\n",
       "            511,   102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 6902,  857,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 2207, 3198,  952, 3241,  677, 1762, 7931, 1767, 2523, 2159, 3211,\n",
       "          2218, 5543, 4692, 6224, 3837, 3215, 8024, 3300, 3198, 6820, 5543, 4692,\n",
       "          6224, 3837, 3215, 7433,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 2913,  857,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 4788, 1776, 4868,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 1353, 3633, 2769,  679,  928,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 3867, 1927, 2418, 6421,  679, 2512, 1510, 2769, 1126, 1283, 4638,\n",
       "          2339, 6598,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 5549, 1103, 3215, 8024,  704, 2094, 3215,  833, 3867, 1927, 1408,\n",
       "          8043, 6820, 3221, 3719, 2608, 4638, 2100, 1762, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101,  868,  711, 4895, 1922, 7345, 3297, 6818, 4638,  671, 7578, 6121,\n",
       "          3215, 8024, 3717, 3215, 3187, 3791, 5564, 4895, 5632, 2346, 4638, 6758,\n",
       "          6887,  738, 3187, 3791, 3291, 7479, 6818, 1922, 7345, 8024,  794, 3297,\n",
       "          1159, 4638, 2682, 6206, 1343, 7479, 6818, 8024, 1168, 3297, 5303, 4638,\n",
       "           809, 6905, 2542, 1333, 3300, 4638, 6758, 6887, 4685,  845, 6817, 6121,\n",
       "          8024,  955, 4507, 1921, 3152, 4638, 3519, 2573, 3341, 1616, 2900,  782,\n",
       "           680,  782,  722, 7313,  771, 6823,  771, 6818, 4638, 2658, 2697, 1068,\n",
       "          5143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 1774, 5367,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101,  679, 6589, 4510,  720,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 3180, 3952, 1343,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6782715640990928131',\n",
       "  'input_ids': tensor([ 101, 2769,  121,  137,  137,  127,  100,  130,  130, 8430, 8160, 8188,\n",
       "          8136,  130,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6998443161127243039',\n",
       "  'input_ids': tensor([ 101, 6760, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6998443161127243039',\n",
       "  'input_ids': tensor([ 101, 5401, 1957, 3241,  677, 1962,  791, 2399, 4696, 3221,  679, 2398,\n",
       "          1127, 4638,  671, 2399, 8024, 1962, 1962,  924, 7028,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893079981358861581',\n",
       "  'input_ids': tensor([ 101,  872,  812, 6789, 5736,  749, 8024, 1403,  872,  812, 5636,  809,\n",
       "          3297, 2300, 7770, 4638, 3143, 2692,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893079981358861581',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 1139, 6356, 8024, 6963, 6206, 2398, 2398, 2128, 2128,\n",
       "          1726, 3341, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893079981358861581',\n",
       "  'input_ids': tensor([ 101, 1403,  872,  812, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893079981358861581',\n",
       "  'input_ids': tensor([ 101, 6789, 5736,  749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893079981358861581',\n",
       "  'input_ids': tensor([ 101,  791, 1921, 3221, 1921, 3823, 1920, 4255, 4156, 4638, 1063, 1453,\n",
       "          2399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6671891732524829965',\n",
       "  'input_ids': tensor([ 101, 1963, 3634, 1107, 4030,  671, 1898, 1386, 2622,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6671891732524829965',\n",
       "  'input_ids': tensor([ 101, 1377,  809, 2458, 2245, 4684, 1285, 3322, 3131, 2844,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6671891732524829965',\n",
       "  'input_ids': tensor([ 101,  782, 2552, 1107, 4030,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6671891732524829965',\n",
       "  'input_ids': tensor([ 101, 1511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '6671891732524829965',\n",
       "  'input_ids': tensor([ 101, 6929, 7027, 4638,  782, 3696, 1557, 8024, 2218, 6821, 4157, 5162,\n",
       "          6574,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1420, 1168, 8290, 4638, 6929,  702, 1898, 7509, 8024, 2552, 6963,\n",
       "          2998, 1762,  671, 6629,  749, 8024, 1963, 3362, 3221, 2769, 8024, 2769,\n",
       "          3690,  679, 4310, 6499, 6375, 6121, 8024, 2769, 4638, 7730, 7724, 6395,\n",
       "          1372,  966, 8262, 1779, 8024, 6656, 6929, 6205,  680, 4495, 1462, 6612,\n",
       "          6651, 4638,  782, 4685, 3683,  671, 3152,  679,  966, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 4802, 2141, 3791, 2526, 2100, 1762, 5375, 7379, 1416, 8013, 1353,\n",
       "          3633, 2769, 1762, 2593, 6402, 1139, 6402, 6878, 1168, 1853, 6756, 4638,\n",
       "          3198,  952, 8024, 3766, 3300,  671,  702,  782, 6375, 6814, 8024, 1217,\n",
       "          1853, 4638,  948, 3221, 3300, 6814, 8024, 2923, 2552, 2170, 4638,  511,\n",
       "          4852,  833, 5162, 6574,  738, 3221, 2418, 2496, 6822,  671, 3635, 2990,\n",
       "          7770,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1071, 2141, 6821,  738,  679, 2597, 6929,  763, 1385, 3322,  511,\n",
       "          6929,  720, 1843,  511, 6662, 6929,  720, 2207,  511, 3418, 3315, 3766,\n",
       "          3791, 6375, 1963, 3362, 5543,  976, 1139,  671,  702, 2418, 2593, 6756,\n",
       "          6887, 2218, 1962,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 6121,  782, 8038, 2769, 3766, 7231, 1557, 8013, 1385, 3322, 8038,\n",
       "          2769,  738, 3766, 7231, 1557, 8013, 3131, 2844, 6756, 8038, 2597, 2769,\n",
       "          1492, 8013, 2642, 5442, 8038, 3221, 2769,  679, 2190, 8024, 1044, 6624,\n",
       "           671, 3635, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1920, 2157, 6963, 2682, 6375,  511,  852, 3221, 6963, 6375,  782,\n",
       "          6121, 3566, 6887, 3157, 7716, 5296, 1305,  857,  749, 8024, 4851, 6375,\n",
       "          6121,  782,  511, 6121,  782, 1567, 3198,  952, 5543, 4851, 6375, 3749,\n",
       "          6756, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1963, 3362,  872, 1728,  711, 6375,  749, 8290, 3300, 5385, 3621,\n",
       "          1343,  769, 6356, 3221,  679, 5314, 1905, 5385, 4638, 8024, 3152, 4683,\n",
       "          2218, 5050,  749, 8024, 6820, 3766, 1920, 5554,  511,  782, 4956, 4956,\n",
       "          1762, 5554, 6150, 8024,  782, 2168,  738, 2168, 1762, 5554, 6150,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101,  679, 6206, 6887, 2548, 5308, 3373, 8024,  872, 6432, 6756, 3187,\n",
       "          2658, 4638, 3198,  952,  872, 3300, 2682, 6814, 6121,  782, 3291, 3187,\n",
       "          2658, 1408, 8043, 4852,  833, 2590, 5335, 4638, 4802, 3719, 6823, 6963,\n",
       "          3221, 1398, 2658,  924, 2844, 2483, 5442, 8024,  852,  872,  738, 2458,\n",
       "          6756, 8013, 3300, 4638, 3198,  952,  738,  679, 3221,  872, 2682, 2582,\n",
       "          3416, 2218, 2582, 3416, 4638, 8013, 1673,  677, 6432, 4638, 1914, 1962,\n",
       "          1420, 4638,  782, 8024, 4385, 2141, 2940,  749,  872, 3313, 2553, 5543,\n",
       "           976, 1168, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2769,  833, 1440, 6401,  782,  812, 6375, 6887, 8024, 3300, 3131,\n",
       "          2844, 6756,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 3766, 4692, 1168,  782, 6121, 6887, 1408, 8043, 4385, 1762, 4638,\n",
       "          6756,  712, 2458, 6756,  679, 2159, 3211, 8024, 6206, 4851, 6375, 6121,\n",
       "           782, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2990, 6379, 8290, 3121, 6822, 4684, 1285, 3322, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1962, 6413, 6963,  833, 6432, 8024, 2398, 2382, 4638,  671, 1921,\n",
       "          2600, 5543, 1420, 6224, 3131, 2844, 6756, 1510, 8024, 3766,  782, 4761,\n",
       "          6887, 7027, 6804, 1168, 2419, 3300, 3766, 3300, 4567,  782, 8024, 1377,\n",
       "           809, 5468, 5143,  769, 6356, 2376, 2564, 1905, 4415, 8024, 1377,  809,\n",
       "           678, 6756,  782, 1168, 1184, 7481, 6432, 3209, 2658, 1105, 8024, 2769,\n",
       "          4685,  928, 6963,  833, 6375, 4638, 8024, 2111, 2094,  677, 2110, 3680,\n",
       "           702, 3299, 3413, 7305, 1366, 6963, 3221, 1963, 3634, 8024, 1168, 2419,\n",
       "          6443, 4638, 7231, 8024, 1385, 3322, 2682, 6375, 6662, 6121,  782,  679,\n",
       "          6375, 1327, 6814, 1343,  720,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 6821, 2218, 3221, 4851, 6375, 6121,  782, 8024, 4385, 1762, 4638,\n",
       "          6121,  782, 3566, 6121, 7464, 6887, 8024, 5052,  872, 5543,  679, 5543,\n",
       "          1172,  857, 6756, 8024, 4692, 6963,  679, 4692, 8013, 2792,  809, 6873,\n",
       "          2533, 2769,  743,  749,  697, 4636,  674, 4638,  676, 5442, 7372,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1184, 7481, 3221, 2111, 2094, 1400, 7481, 3221, 4567,  782,  511,\n",
       "           697, 7410, 6848, 2885,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1071, 2141, 3131, 2844, 6756, 3297, 1920, 7397, 4809, 3221, 6662,\n",
       "           704, 7313, 7344, 2844, 2882, 8024, 2458, 6814, 4638, 6963, 3300,  860,\n",
       "           833, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 1762, 3413, 7305, 1366, 8024, 5445, 6858, 6814,  782, 6121, 6887,\n",
       "          4638, 1772, 3221, 2110, 4495, 1469, 2157, 7270, 8024,  886, 1184, 7481,\n",
       "          6756, 6775, 3187, 3791, 1184, 6375, 8024,  702,  782, 6230, 2533, 6421,\n",
       "          3413, 3766, 3300, 3249, 1350, 6912, 6375, 3131, 4495, 6858, 6887, 4761,\n",
       "          6399, 8024, 2110, 3413, 2128, 1059,  860, 5143,  679, 1916, 2130, 1587,\n",
       "          8024, 1086,  671,  702, 3221, 2769, 6371,  711, 7370,  749, 7770, 6862,\n",
       "          8024, 1744, 6887, 6963, 2418, 6421, 6392, 5390,  671, 3340, 5165, 2593,\n",
       "          6858, 6887, 8024, 2798, 6858, 3300, 3126, 6237, 1104, 4294, 3654, 6756,\n",
       "          6775, 6858, 6121, 7309, 7579,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101,  679, 6206, 6887, 2548, 5308, 3373, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2456, 6379, 3680,  702, 1814, 2356, 4638, 7716, 6662, 6963, 6206,\n",
       "          3300,  671, 3340, 4495, 1462, 6858, 6887, 8013, 1728,  711,  679, 1377,\n",
       "          5543,  976, 1168, 3680,  702,  782, 6963, 6375, 6121, 4294, 4905, 6756,\n",
       "          6775, 4638, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 6432, 2141, 6413, 4696, 3766, 1765, 1036, 6375, 6820, 1843, 1762,\n",
       "          6929,  720, 6823, 6206, 3221,  122,  119,  123, 6775, 6756, 5507, 2137,\n",
       "          2218, 6375,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 3402, 3408, 2128, 6163, 4638, 1168,  855,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101,  711,  784,  720,  679, 3058, 2458, 3178, 6804, 2844, 3408, 8043,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 4692, 6821,  702, 6228, 7574, 8024, 5018,  671, 2682, 4761, 6887,\n",
       "          4638, 2218, 3221, 1525,  702, 1765, 3175, 4638,  782, 2798,  511, 4696,\n",
       "          4638, 3221, 3187, 6427,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2418, 6421, 4684, 2970, 1396, 7218, 7730, 7724, 6395, 8024, 5303,\n",
       "          6716,  679, 2533, 5440, 1357,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2157, 2247,  809, 1400, 5507, 2137,  679,  833, 5314, 3131, 2844,\n",
       "          6756, 6375, 6662,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 2682, 1215, 3791, 1568, 8024, 2940, 2768, 4684, 1285, 3322, 2970,\n",
       "          4567,  782, 8024,  679, 1843,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6893044994064600332',\n",
       "  'input_ids': tensor([ 101, 3131, 2844, 6756, 1184, 7481, 6756, 1059, 6956, 2674, 5385,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  679, 6887, 2548, 5308, 3373, 8024, 1315,  886, 1961,  812, 6842,\n",
       "          1316,  738, 5543, 4415, 6237, 8024, 3684, 4994, 6963, 3221, 3249, 6858,\n",
       "           782,  511, 2792,  809, 1079, 2552, 3291, 1217, 3143,  877, 2697, 4080,\n",
       "           704, 1744, 1278, 1218, 2339,  868, 5442, 8024, 1235,  754, 1938, 4346,\n",
       "          8024, 1315,  886, 1184, 3175, 6929,  720, 5736,  510, 6929,  720, 5168,\n",
       "          8024,  800,  812,  793, 4197, 1780, 2127,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 7471, 4482, 1378, 2600, 5050, 2682,  749,  702, 1962, 4638, 5093,\n",
       "          1366, 3341, 2973, 7652, 2219, 2217,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 4415, 4507,  679, 1041, 1146, 8024,  704, 1744, 4638, 2844, 1894,\n",
       "          3766, 2111, 2094, 1408, 8043, 2769, 1372, 4761, 6887,  704, 1744,  782,\n",
       "          3696, 1072, 3300, 1938, 4346, 5125, 4868, 8024, 5650, 2207, 2157, 7560,\n",
       "          1920, 2157, 8024, 1728, 3634, 8024, 2769,  812, 2798, 5543, 1066, 1398,\n",
       "          2773, 5526, 4554, 2658,  511, 6821, 2218, 3221,  704, 1744, 5125, 7767,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  679, 3221, 2769, 6887, 2548, 5308, 3373,  100,  100, 1963, 3362,\n",
       "          3221,  704, 1744, 4638, 2844, 1894, 8024, 2418, 6421, 5635, 2208, 3300,\n",
       "           671, 1288,  782, 6848, 2885,  679,  833, 6791, 5466,  100,  100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  137, 5010, 1677, 1677, 8038, 1567,  738,  679, 6432, 8024,  711,\n",
       "          2769,  812,  704, 1744, 4638,  671, 5296, 2773, 1894,  812, 7961, 2958,\n",
       "          1217, 3779, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 1315,  886, 1744, 2157, 7444, 6206, 6820, 6206, 2902, 1333, 6369,\n",
       "          1153, 4895, 5466, 8024, 6821,  702, 6237, 7025, 3291, 1217, 6432,  679,\n",
       "          6814, 1343,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 6432, 2141, 6413, 4385, 1762, 6624, 2218,  679, 3221, 3198,  952,\n",
       "           511, 3297,  698, 7028, 4638, 3198,  952,  872, 6848, 2885, 4895, 2458,\n",
       "           511,  679, 2682, 1914, 6432,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 3209, 3227, 4638, 2190, 3683, 8024, 2769,  812, 4638, 4635, 6132,\n",
       "          1921,  886, 3221, 1914,  720, 4638,  836, 1920, 1557, 8024,  711, 2769,\n",
       "           812, 4638, 1278, 1218,  782, 1447, 4157, 6614, 8024, 3300,  872,  812,\n",
       "          2769,  812, 7734, 1000,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  137, 2401, 4886, 3341, 1168, 8038, 6206, 3221,  704, 1744, 4638,\n",
       "          2844, 1894, 8024,  671, 2137,  679,  833, 1762, 6821,  702, 3198,  952,\n",
       "          6791, 5466, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 2769,  812, 1184, 5296, 4638, 2844, 1894,  812,  679, 5168,  720,\n",
       "          8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  782, 2797,  679, 6639, 3766,  782, 3296, 6133, 3221, 2523, 4385,\n",
       "          2141, 4638, 7309, 7579, 2658, 1105, 1469,  704, 1744,  679,  671, 3416,\n",
       "          8024, 7506, 1744, 1469,  704, 1744,  671,  702, 4689, 2345,  679, 1914,\n",
       "          1920, 8024, 8262, 1914,  782, 4802, 6402, 1469, 3636, 3727, 2658, 1105,\n",
       "           671, 3416,  749, 8024, 3636, 3727, 6821,  720, 1914,  782, 1872, 3001,\n",
       "          6820, 3221, 2564,  679, 6814, 3341,  511,  679, 6206, 6887, 2548, 5308,\n",
       "          3373,  749,  679, 4293, 2816, 1744, 2157, 4554, 2658, 7481, 1184, 6963,\n",
       "           679, 1962, 6814,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 6821, 2399, 1928, 3766, 1914, 2208, 1377,  809,  928, 2533, 6814,\n",
       "          2054,  860,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 6369, 1153, 6628,  679,  677, 1359, 1265, 4638, 6887, 4415, 2769,\n",
       "          4692, 6443,  679, 2743,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  752,  679, 1068, 2346, 7770, 7770, 2899, 6629, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 6237, 7025, 2218, 3221, 2973, 7652,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 1506, 8024, 1506,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 6237, 7025, 2218, 3221, 2973, 7652, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 5632, 4507,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 4385, 2141,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101,  752,  689, 5356,  679, 6206, 1568, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 1963, 3634, 8013,  711,  704, 1744, 1278, 2844,  782,\n",
       "          1447, 4157, 6614, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 2990, 7770, 4635, 6132, 1921,  886, 4638, 2521, 6878,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 5543, 2870,  671,  702, 1914, 3299,  711,  862,  679, 5543, 1086,\n",
       "          2870,  671,  697,  702, 3299, 1450, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732011912634125575',\n",
       "  'input_ids': tensor([ 101, 2703, 2792, 3300, 1939, 2773, 1762,  671, 5296, 4638,  782, 6963,\n",
       "          5543, 6158, 3946, 3382,  809, 2521,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1921, 1920, 4638, 5010, 6413, 8024, 1282, 1063,  702,  671, 6629,\n",
       "          6791, 5466, 6369, 1153, 1962, 4638,  511, 2769, 6820, 3221,  928,  749,\n",
       "          1416, 8024, 1353, 3633, 6656, 2769, 3766, 1068, 5143,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 6821, 3221, 6912, 6469, 8024, 1048, 2533, 5314,  671, 5296,  782,\n",
       "          1447,  772, 4495,  679, 5679, 2590, 2682, 8013, 1920, 2157, 6963, 2743,\n",
       "          2533, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1457, 1457, 8024, 3221, 3297, 1962, 4638, 5031, 1908,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1728,  711, 4554, 2658, 6791, 5466,  872,  738,  679, 5543, 6432,\n",
       "          1557, 8024, 1914,  696,  782, 1557, 8013, 2769,  812, 3221, 6847, 6121,\n",
       "          5445,  677, 8024,  872,  812, 3221, 1068, 7241, 4638, 3198, 1174, 4638,\n",
       "          5519, 2598, 8024, 6842, 5367,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 5632, 2346, 2157, 1278, 2844, 2586, 3647, 6791, 5466, 8024, 2769,\n",
       "           812, 1744, 2157, 4638, 2140, 6564, 1283,  674,  679, 6206,  955, 1139,\n",
       "          1343, 1557, 8024, 1961,  812,  738, 3221, 4266,  779, 8024, 1036, 2094,\n",
       "          8024, 3678,  779, 8024, 1957, 1036,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 6791, 5466,  749,  738, 4415, 6237, 8024,  976, 1962, 5632, 2346,\n",
       "          2218, 6121, 8024,  711,  784,  720, 6206, 3724, 1166,  782, 2768,  711,\n",
       "          5739, 7413, 8043,  679, 6206, 5729, 6569, 1166,  782, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101,  679, 5052,  784,  720, 1333, 1728, 8024, 1762, 4554, 2658, 1920,\n",
       "          3127, 2496, 1184, 8024,  738, 6206, 1780, 2898, 1044, 2834, 4567, 3681,\n",
       "          1086, 6432,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 2157,  682,  679, 1377, 1912, 2813,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 6821, 6413, 2586,  872, 5632, 2346, 6963,  679,  928, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1166, 6237, 7025, 8024, 6237, 7025, 2218, 3221, 2973, 7652,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101,  704, 1744, 8024, 7506, 1744, 1353, 2345, 1922, 1920,  749, 8013,\n",
       "           704, 1744,  782, 1403,  686, 4518, 6395, 3209, 2769,  812, 1730, 5310,\n",
       "          8013, 1071, 2124, 4638, 1744, 2157,  872,  812, 5632, 2346, 5632, 2110,\n",
       "          1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101,  679, 6237, 7025, 6820, 1962, 4157, 8024,  671, 6237, 7025, 6963,\n",
       "          3209, 4635,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1744, 2157, 3300, 7410, 8024, 6820, 3221, 6791, 5466, 8024, 5445,\n",
       "           684, 3221, 7415,  860, 6791, 5466,  877, 3302,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1962,  749, 2769,  812, 6963,  928,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1511, 8024, 2769,  928, 1962, 1416,  511,  800,  812, 4638, 6848,\n",
       "          2885, 6963,  833, 2203, 7028, 8024,  679,  671, 3416, 4638, 3221,  704,\n",
       "          1744, 2844, 1894, 3221, 1091, 4509, 6435, 1343, 4638, 8024, 5445,  800,\n",
       "           812, 3221, 6158, 6833, 2970, 1358, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 7506, 3152,  704, 3300, 3187,  100, 3148, 6122,  100,  753, 2099,\n",
       "          8043, 1963, 3362, 3300, 8024, 6929,  720, 8024, 6435, 2802, 1139,  100,\n",
       "          2376, 4708, 3148, 6122,  100, 1724, 2099,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1638, 1638, 8024, 3221, 1728,  711, 3766, 3198, 7313, 2372, 2111,\n",
       "          2094, 8024, 1638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 6791, 5466, 2218, 6791, 5466, 1353, 3633,  679, 5052, 2769,  812,\n",
       "          4638,  752, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1962, 2341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 3647, 6206, 7481, 2094, 3833, 1358, 5389, 8024, 2714, 2714, 3053,\n",
       "          4708, 1416, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 6237, 7025, 2218, 3221, 2973, 7652,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 8121,  702, 1398, 3198, 6791, 5466,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 1963, 3362,  704, 1744, 5318, 2190,  679,  833, 6821, 3416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 7506, 1744, 1217, 3779, 2769,  812, 4263,  872, 2697, 6468, 3636,\n",
       "          3727, 2935, 3621,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6730921689619746059',\n",
       "  'input_ids': tensor([ 101, 2208,  758, 1283, 2399, 4638, 3152, 1265,  837, 2824, 8024, 5543,\n",
       "          6821, 3416, 2347, 5307, 2523, 1962,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 3680,  702, 2054,  860,  782, 6963, 2418, 6421, 3315, 4708, 2190,\n",
       "          5408,  830, 2190, 1744, 2157, 2190,  752, 2141, 6566, 6569, 4638, 6241,\n",
       "          6389, 1355, 6134, 8024, 1415, 1156, 1744,  782,  671, 1456, 4638, 7734,\n",
       "          1000, 4638, 6241, 6389,  738,  833, 2938, 2154, 1744, 2157, 4638, 2501,\n",
       "          6496,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 2769, 6206, 3221, 2844, 1894, 8024, 1762, 6821,  702, 1314, 7410,\n",
       "          1068, 1928, 8024, 4862, 1744, 1469, 1398, 5528, 6963, 7444, 6206, 2769,\n",
       "          4638, 3198,  952, 2769, 5318,  679, 6842, 5367, 8024, 6816, 7410, 5445,\n",
       "           677, 8024, 1525, 2586, 1184, 3175, 3221, 2647, 2304, 8024, 2769,  738,\n",
       "           833, 5106, 6716, 4810, 7755, 8024, 1762, 2792,  679, 2667, 8013, 7506,\n",
       "          1744,  782, 8024, 2769, 4692,  679, 6629, 8013, 3766, 3300, 3152, 1265,\n",
       "          2419, 5943, 8024, 3766, 3300, 1938, 4346, 5125, 4868, 8013, 1290, 1909,\n",
       "          1036, 1957, 2798, 3221, 1962, 3416, 4638, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 6821, 3221, 5314, 1278, 4545, 6956, 7305, 1469, 6929,  763, 2844,\n",
       "          1894, 2823, 1378, 7348,  678, 1557, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 1963, 3362, 3221,  704, 1744,  782, 3315, 3341, 1114, 1906, 6791,\n",
       "          5466,  671, 4692, 4554, 2658, 3341,  749, 8024, 4684, 2970, 2218,  679,\n",
       "          6791, 5466,  749, 8013, 7506, 1744,  782,  671, 4157, 1938, 4346, 5125,\n",
       "          4868, 6963, 3766, 3300,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 6821, 3221, 1059,  782, 5102, 7444, 6206, 1066, 1398, 2190, 2834,\n",
       "          4638, 4554, 2658, 8024,  679, 6206, 5862,  759,  678, 4767, 8024, 2401,\n",
       "          4135,  727, 4877,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 2769,  679, 4761, 6887, 3221,  679, 3221, 6792, 6469, 8024, 2769,\n",
       "          1372, 4761, 6887,  704, 1744,  782, 1762, 4554, 2658, 7481, 1184, 3719,\n",
       "           679, 6842, 5367,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 1044,  679, 6432, 5783, 6289, 8024, 7674, 1044, 2190, 5632, 2346,\n",
       "          2218, 3221,  671, 4905,  907, 6802, 8024,  852, 2418, 6421, 2203, 7028,\n",
       "          1392,  782, 6848, 2885,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 4696, 2341, 1506, 8024, 8121, 1399,  671, 6629, 6791, 5466,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 6821, 3416, 2798, 5050, 1962, 2844, 1894,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 1457, 1457, 1377,  928, 2428, 1922,  856,  749,  679,  833, 5356,\n",
       "          3125,  752,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 6369, 1153, 6791, 5466, 8043, 6369, 1153, 8043, 2769, 1343, 2399,\n",
       "          2218, 6369, 1153,  791, 2399, 6814, 2399, 1762, 5439, 2157, 4717,  671,\n",
       "           702, 3299,  679, 1139, 7305,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 3209,  934, 3404, 6887, 3266, 3941, 7357,  797,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101,  679, 5052, 2582, 3416, 1372, 6206, 5543, 1780, 2898, 1168, 3297,\n",
       "          1400, 6963, 3221, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 4554, 2658, 5310, 3338,  800,  812, 2218,  679, 6791, 5466,  749,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 6821, 6237, 7025, 2207, 2111, 2094, 6963, 7745,  679,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 1217, 3779,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101, 4554, 2658, 3187, 1744, 4518, 8024, 2361, 3307, 6821, 1767,  782,\n",
       "          5102, 4135, 7410, 3193, 3189, 3141, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799691151185071363',\n",
       "  'input_ids': tensor([ 101,  679, 4500, 6237, 7025,  749, 8024, 6237, 7025, 2218, 3221, 2973,\n",
       "          7652,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1457, 1457, 8024, 1377, 5010, 8013, 1068, 7241, 3198, 1174, 6820,\n",
       "           679, 3221, 3675, 4197, 1104, 4197, 4638, 6624,  749, 8043, 6206, 3221,\n",
       "          2940,  749,  704, 1744, 2844, 1894, 1166, 6432, 6820, 3766, 4895, 2458,\n",
       "          8024, 1315,  886, 2347, 5307, 6791, 5466, 6963,  833,  721, 3187, 1353,\n",
       "          7560, 4638, 7028, 3173, 4509, 6435, 1726, 1168, 4554, 2658, 1184, 5296,\n",
       "          3118, 3001, 8013, 6821, 2218, 3221, 2769,  812,  704, 1290, 3696, 3184,\n",
       "          4638, 3698, 5688, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 6716,  711,  704, 1744, 2844, 1894, 8024, 2769,  679, 6371, 1377,\n",
       "          1961,  812, 8024,  679, 6389, 1961,  812, 5314, 1139,  784,  720, 4415,\n",
       "          4507, 8024,  809, 1184, 1400, 2637, 2496, 2844, 1894, 8024,  852, 3221,\n",
       "           794, 4554, 2658, 2458, 1993, 1400, 2769, 2218, 1762, 2412, 2401, 2496,\n",
       "          1159, 6848,  749, 2844, 1894,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 5632, 2346, 5314, 5632, 2346, 2823, 1378,  678,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 5307, 6814, 6821, 3613, 3959, 1266, 4554, 2658, 8024, 2798, 6230,\n",
       "          2533, 2769,  812,  704, 1744, 1278, 2844,  782, 1447, 4638,  836, 1920,\n",
       "          8024,  704, 1744,  782, 3696, 4638, 1730, 5310, 8024,  704, 1744, 1217,\n",
       "          3779, 8013, 8013, 3636, 3727, 1217, 3779, 8013, 6789, 5736,  749, 8024,\n",
       "          4635, 6132, 1921,  886,  812,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101,  872,  738, 2218, 7745, 7745, 1004, 2094, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 5507, 2137,  679, 3221, 1728,  711, 4554, 2658, 8024, 3221, 1728,\n",
       "           711,  677, 4408, 3198, 7313, 1922, 7270, 8024, 3766, 3198, 7313, 4212,\n",
       "          7560, 2111, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 3187, 6389,  784,  720, 1333, 1728, 8024, 6821,  702, 3198,  952,\n",
       "          6791, 5466, 2218, 3221,  707, 7347, 6845, 5564,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 2769, 1372, 1068, 2552, 1744,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101,  679, 5052,  784,  720, 1333, 1728, 8024, 2769, 2682, 6432, 2769,\n",
       "          3221,  704, 1744,  782, 8024, 7734, 1000,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1166, 6887, 2548, 5308, 3373,  749, 8024,  782, 2157,  679, 2682,\n",
       "           976,  749, 2523, 5042, 1296, 8024, 2400,  679, 3221, 3680,  702,  782,\n",
       "          6963, 2552, 2100, 1920, 4263, 8024, 2792,  809, 5543, 4415, 6237, 8024,\n",
       "           872, 6848, 2885, 2834, 4554,  782, 2157,  738, 1377,  809, 6848, 2885,\n",
       "          4895, 5466,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 6929,  872, 6432, 6432, 1728,  711, 1567, 8043, 6821,  702, 3198,\n",
       "           952, 6791, 5466, 8024, 4692, 4692, 1068, 7241, 3198,  952, 8024, 6820,\n",
       "          3221,  704, 1744,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 6821, 2218, 3221,  704, 1744,  782, 1469,  872,  812, 4638, 2345,\n",
       "          1166, 8013, 8013, 4692, 4692, 2769,  812,  704, 1290, 4638, 1921,  886,\n",
       "          8013, 8013, 8013, 2769,  704, 1290, 7734, 1000, 8013, 2769, 7734, 1000,\n",
       "          8013, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1457, 1457, 8024, 1377, 5010, 8013, 1068, 7241, 3198, 1174, 6820,\n",
       "           679, 3221, 3675, 4197, 1104, 4197, 4638, 6624,  749, 8043, 6206, 3221,\n",
       "          2940,  749,  704, 1744, 2844, 1894, 1166, 6432, 6820, 3766, 4895, 2458,\n",
       "          8024, 1315,  886, 2347, 5307, 6791, 5466, 6963,  833,  721, 3187, 1353,\n",
       "          7560, 4638, 7028, 3173, 4509, 6435, 1726, 1168, 4554, 2658, 1184, 5296,\n",
       "          3118, 3001, 8013, 6821, 2218, 3221, 2769,  812,  704, 1290, 3696, 3184,\n",
       "          4638, 3698, 5688, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 5335, 2844,  671,  702, 1744, 2157, 4638, 2203,  698,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1398,  671, 7313, 1278, 7368, 8121, 1399, 2844, 1894, 1398, 3198,\n",
       "          2990, 1184, 6791, 5466, 2586, 3221, 3766, 6821,  720, 2341, 1394, 4638,\n",
       "           752, 1036, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 2586, 2471, 6629, 2607, 2707, 8024, 3634, 1765, 3187, 7213,  676,\n",
       "          4636,  697,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101,  782, 2157, 6432,  749, 3221, 1728,  711,  678, 4408, 3241, 8024,\n",
       "          3766, 3198, 7313, 4212, 7560, 2111, 2094,  511, 6443, 6432, 1728,  711,\n",
       "          4554, 2658,  749, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101,  711,  784,  720, 2769,  812,  704, 1744, 4635, 6132, 1921,  886,\n",
       "           812, 6791, 5466,  749, 6820, 1726, 3341, 6435, 2773,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 6469, 6241,  679, 6469, 6241, 4638, 8024,  782, 3221, 4895, 2458,\n",
       "           749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 2590, 2682, 2339,  868, 6820, 3221,  976, 6858,  749, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 3683,  679,  749, 2769,  812,  704, 1744,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1147,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 2190, 1435, 8024,  782, 2157, 3315, 3341, 2218, 3766, 6432, 1728,\n",
       "           711, 6821,  702, 6791, 5466, 1557, 8024,  782, 2157, 3221, 1728,  711,\n",
       "          2157, 7027, 3300,  752, 8024, 2111, 2094, 3766,  782, 4692,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 6469, 6241,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799850000609283335',\n",
       "  'input_ids': tensor([ 101, 1506, 1506, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 2769,  812, 2844, 1894, 4638, 2111, 2094,  131, 1968, 1968, 6432,\n",
       "          4638, 2769, 6963,  976, 1168,  749, 8024, 1377, 1968, 1968,  784,  720,\n",
       "          3198,  952, 1726, 2157, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 1469, 2769,  812, 3300,  784,  720, 1068, 5143, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101,  679, 5052, 2582,  720, 6432,  704, 1744, 2844, 1894,  679, 1912,\n",
       "           955,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 1536, 8013, 4696, 4685, 3221, 3297, 7410, 4761, 6887, 4638,  928,\n",
       "          2622,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 2769,  679,  928,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 7583,  511,  511,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 6963, 3221, 1962, 3416, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 2769, 3221,  794, 3341, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 2769, 4638, 2140, 2140, 6432, 8024, 2769,  784,  720, 6963,  679,\n",
       "          6206, 8024, 2769, 2218, 2682, 6206, 1968, 1968, 8024, 4746, 7313, 2218,\n",
       "          3801, 1944,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 1762, 2769,  812,  704, 1744, 8024, 2682, 6791, 5466, 8024, 7481,\n",
       "          2190, 4554, 2658,  738,  833, 1780, 2898, 1168, 4554, 2658, 1400, 8024,\n",
       "          7370, 7478, 5632, 2347,  948,  678,  749, 8024, 6821, 2218, 3221,  704,\n",
       "          1744,  782, 4638, 2658, 2577, 2792, 1762, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 6632, 2851, 6632, 7946,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xn6itkb8szn66a',\n",
       "  'input_ids': tensor([ 101, 2823, 1779, 2357, 4667,  677, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101,  671, 2458, 1993, 7506, 1744, 3766, 3300, 3189, 3315,  698, 7028,\n",
       "          8024,  852, 3221,  800,  812,  679, 4397, 2667, 2769,  812,  704, 1744,\n",
       "           751, 1357, 1139, 3341, 4638, 3198, 7313, 8024, 2792,  809, 4385, 1762,\n",
       "          4554, 2658, 4255, 1355, 2707,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 4635, 6132, 1921,  886, 3315, 3341, 2218, 3221,  702, 4868, 1760,\n",
       "          4638, 5503, 2345, 8024, 2523, 1914,  782, 2682, 5440, 6822, 1343, 2496,\n",
       "          1278, 4495, 6963, 3221,  711, 7410, 4638,  752,  511,  981, 2209,  671,\n",
       "           697,  702,  782, 6791, 5466, 6820, 2658, 3300, 1377, 1333, 8024, 1377,\n",
       "          7415,  860, 6791, 5466, 2218, 3221, 1762, 6845, 6912,  749,  511, 6820,\n",
       "          3221, 2769,  812,  836, 1920, 4638, 4862, 1744, 1962, 8024,  671, 3175,\n",
       "          3300, 7410, 1061, 3175, 3118, 3001,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 1912, 1744,  782, 2586, 3647,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101,  872, 4696, 1377, 2589, 8024, 3766, 6397, 6389, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 1457, 1457, 8013, 1059,  686, 4518, 6963, 4761, 6887, 2582,  720,\n",
       "          1726,  752, 8024,  862, 2553, 1450, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 3766, 3683, 6772, 2218, 3766, 3300, 2345, 1166,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 4385, 1762, 4638, 2054,  860, 2845, 6887, 4696, 4638, 3221, 2800,\n",
       "          3304, 6837, 4895,  671, 1921,  671,  702, 3173, 7319, 5018,  753, 1921,\n",
       "          3341,  671,  702, 1196, 2658, 1353, 6760, 4197, 1400, 1348, 1086, 1353,\n",
       "          6760, 3297, 1400, 5018,  676, 1921, 8038, 3418, 3315, 3766, 6821, 1726,\n",
       "           752, 2347, 6792, 6469,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 6963, 3221,  704, 1744, 4638, 1435, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 2769, 4294, 2682, 4761, 6887, 8024, 6821,  702, 4170, 1514, 1624,\n",
       "          8024, 3221, 6443, 1548, 4638, 8024, 6468, 6468,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 6821, 2218, 3221, 2792, 6458, 8013, 1920, 7506, 4638,  782, 3696,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 2586, 3647, 2218, 3221, 2586, 3647, 8024, 3187, 7444, 2823,  955,\n",
       "          1366,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799625871759133967',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 4635, 6132, 1921,  886,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799784527892925704',\n",
       "  'input_ids': tensor([ 101, 6821, 2218, 3221,  704, 1744, 8024,  686, 4518, 1546,  671, 8024,\n",
       "          2126, 2136, 1546,  671, 8024,  966, 2533,  872, 1343, 4263, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799784527892925704',\n",
       "  'input_ids': tensor([ 101, 2157, 7599, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 2792,  809, 8024, 2769,  812,  809, 1400, 1914, 1914, 3118, 2898,\n",
       "          1068, 3800, 1493,  812, 3143, 4263, 1278, 2844,  782, 1447, 1416, 8024,\n",
       "          2208, 5314, 6929,  763, 3625, 3215, 3209, 3215, 4157, 6614, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 3300,  784,  720, 1962, 6569, 2597, 4638, 6821, 3221,  800,  812,\n",
       "          4638, 3326, 1164,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 6963, 6651,  704, 1744,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  818,  862,  782, 6963, 3300, 5632, 2346, 4385, 1762, 3326, 1164,\n",
       "          8024, 1372, 3221, 1961,  812, 6848, 2885, 1400, 5442, 8024,  852, 3221,\n",
       "           738, 6206, 2203, 7028,  782, 2157, 4638, 3326, 1164,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 2769, 1920,  704, 1744, 4638, 1278, 4495, 2844, 1894, 6820, 2845,\n",
       "          1399, 1343, 2834, 4554,  511, 2828, 3131,  782, 3123, 1762, 5018,  671,\n",
       "           855, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 6656, 1493,  704, 1744, 4638, 4635, 6132, 1921,  886, 3221, 3766,\n",
       "          3300, 1215, 3791, 3683, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  711, 2769,  812,  704, 1744, 4635, 6132, 1921,  886, 4157, 6614,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 1184, 6822, 1469, 1400, 6842, 3221, 2792, 3300,  782, 4638, 3326,\n",
       "          1164, 8013,  818,  862,  782, 6963, 1377,  809, 5632, 4507, 6848, 2885,\n",
       "          8024,  852, 2769,  812, 4638, 1278, 1218, 2339,  868, 5442, 6848, 2885,\n",
       "           749, 1184, 5442, 8024, 1403,  800,  812, 5636, 3143, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  711, 2769, 1744, 4638, 4635, 6132, 1921,  886, 4157, 6614,  511,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 1372, 3300, 2769, 1744, 4638, 2798, 1377,  809, 4917,  711, 4635,\n",
       "          6132, 1921,  886,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 2397, 4638, 4023,  778, 8024, 4157, 6614, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  707, 7347, 5564, 6845,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 6821, 2218, 5543, 4692, 1139,  671,  702, 1744, 2157,  782, 3696,\n",
       "          4638, 6569,  818, 2552,  749, 8024, 2412, 2401, 4495, 1762,  704, 1744,\n",
       "          8024, 2361, 3307, 4554, 2658, 3193, 4157, 6814, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  782, 2157, 2054,  860, 2347, 5307, 6792, 6469,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  679, 5052, 3221,  679, 3221, 1728,  711, 3173, 5511, 4142, 6791,\n",
       "          5466, 8024, 1372, 6206,  872, 1762, 6821,  702, 5688, 7755, 4706,  677,\n",
       "          6791, 5466, 8024, 2600, 5314,  782,  671, 4905, 2682, 6496, 4958, 7313,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 4635, 6132, 1921,  886, 8024, 6847, 6159, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 6820, 3221, 2769,  812,  704, 1744, 4638, 2844, 1894, 5314, 1213,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 6821, 4905,  752, 2658, 2582,  720, 6432, 1450, 8024,  794, 1166,\n",
       "          4638, 6235, 2428, 4692,  738, 3766, 7231, 8024, 7231, 4638, 3221, 3209,\n",
       "          4761, 6887, 3300, 4567, 3681, 6820,  679, 7023, 1357, 2974, 3177, 4638,\n",
       "           782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 2792,  809, 4268, 4268, 1343, 1525,  749, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 1914, 3144, 2844, 1894, 2339, 6598,  856, 1168, 3187, 3791, 4495,\n",
       "          2100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 1326, 2154,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 2563, 6381, 6929,  702,  715, 2157, 1139, 6845, 4638,  511,  511,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 3209, 3255, 4638, 6848, 2885,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101,  738, 3221,  782, 2798,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799629050215222542',\n",
       "  'input_ids': tensor([ 101, 1962, 4281, 4638, 6981, 7509, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 1392, 2157, 1392, 2787, 8024,  782,  782,  976, 1962,\n",
       "          7344, 4125,  511,  679, 6206, 1086, 6375, 6821,  763, 2111, 2094, 2772,\n",
       "          5442, 4266,  779, 2772, 4511, 3301, 1351,  679, 6206, 1086, 3868, 7372,\n",
       "           749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 6820, 6963, 3221, 2111, 2094, 2218, 6821, 3416, 6624,  749, 8024,\n",
       "          5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 2111, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 4857, 4876, 2769,  812, 4638, 5739, 7413, 2111, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 4578, 2552,  510, 6963, 3221, 4266, 3678, 4638, 2140, 6564, 8024,\n",
       "          2703,  686,  677, 1086, 3766, 4125, 4135,  510, 3717, 4135,  511, 2703,\n",
       "          2792, 3300, 4638, 2015, 1036, 1139, 6356, 6963, 2398, 2128, 2495, 3341,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 4295, 4291, 6963, 2111, 2094, 8024, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 2111, 2094,  812, 2703, 1921, 1828, 3766, 3300, 4125, 4135,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 5739, 4164, 3719, 6823, 2577, 2573,  872, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 2697, 6468, 5739, 7413, 8024, 3633, 1728,  711, 3300,  749,  872,\n",
       "           812, 8024, 2769,  812, 2798, 5543, 3291, 1962, 4638, 4495, 3833,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 2703, 3680, 3613, 1139, 6356, 6963, 2398, 2128, 2495, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101,  800,  812, 6820, 3221,  702, 2111, 2094, 8024, 3719, 6823, 2577,\n",
       "          2573, 8024, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 6963, 3221, 2111, 2094, 1557, 1962, 2552, 4578, 2703, 1921, 1828,\n",
       "          3766, 3300, 4135, 7410,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 1922, 2358,  749, 8024, 1462, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 1092,  782, 1045, 5783, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 6435,  924,  859,  800,  812,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 5347, 2577, 5739, 7413, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 8024, 5347, 2577, 5739, 4164,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799610199901588743',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 1282,  736, 2259, 1557, 8013, 1914, 1962, 4638, 7471, 3217, 2399,\n",
       "          1290, 8013, 2218, 2137, 3419, 1762, 1568, 1282,  736, 2259,  511, 2207,\n",
       "          5739, 7413,  671, 6662, 6624, 1962, 8013, 2361, 3307, 6821,  855, 3678,\n",
       "           779,  679, 6206, 1922, 7410, 6814, 8013,  872, 3300,  671,  855,  749,\n",
       "           679, 6629, 4638, 1036, 2094, 8013, 1059, 1744,  782, 3696, 4638, 5739,\n",
       "          7413,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 4696, 4638, 1962, 2552, 4578, 8024, 6821, 4905, 4578, 3187, 3791,\n",
       "          2501, 2159,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 2769,  812, 4638,  782, 3696, 5739, 7413, 8013, 8013,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  511, 7350, 2477, 7351,  867,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 3056, 2552, 6162, 5511, 8024, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 2101, 5317, 5317,  704, 4904, 2128, 2434,\n",
       "           738, 4867,  872,  704, 4904, 2571,  727, 3299, 1749,  782, 1730, 1749,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 7208, 6381, 5739, 7413, 2111, 2094,  671, 6662, 6624, 1962, 8013,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 5739, 7413, 1968, 1968, 2552, 1962, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 4692, 4708, 6963, 2552, 4563, 8024, 1962, 1962, 1587, 2521, 4164,\n",
       "          1894, 2157,  782, 8024,  679, 6206, 6375,  800,  812, 1927, 3307,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 3187, 2792, 4519, 2672, 8024,  872, 3221, 2769,  812,\n",
       "          3297, 1377, 3143, 4638,  782, 8024, 1316, 2828, 2650,  839, 4522, 5314,\n",
       "           749, 3297,  779, 4638,  782, 8024, 5739, 7413,  671, 6662, 6624, 1962,\n",
       "          8013, 8024, 2111, 2094, 1968, 1968,  924, 7028, 6716,  860, 8013, 8013,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 3867, 7344, 2773, 1894, 8024, 2399, 7471,\n",
       "          4638, 2111, 2094,  671, 6662, 6624, 1962, 8024, 2703, 1921, 1828, 3766,\n",
       "          3300, 4135, 7410, 3291, 3766, 3300,  872, 5504, 6566, 4638, 6569,  818,\n",
       "           511, 2111, 2094, 4638,  100, 6217, 8024, 3291, 1217,  924, 7028,  511,\n",
       "          6716,  860, 8024,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 2111, 2094,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 4692, 1168, 6963, 3221, 2399, 6768, 4638, 4495, 1462,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4578, 8024, 5739, 7413,  671, 6662, 6624, 1962, 8024,\n",
       "          2157,  782,  924, 7028, 6716,  860,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8024, 2703, 1921, 1828, 3766,\n",
       "          3300, 4125, 2658,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 2552, 4578, 8024, 5636, 3143, 5739, 7413, 8024, 1922, 1377, 2667,\n",
       "           749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8024, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 6821, 2798, 3221, 4696, 3633, 4638, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 7208, 6381, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799647050314075392',\n",
       "  'input_ids': tensor([ 101, 1916,  839, 2552, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 4692, 1168, 6821, 4905, 5739, 7413, 4638, 6228, 7574,\n",
       "          7965, 2094, 6963, 7000, 7000, 4638, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 3143, 4851,  677, 3862, 3867, 7344, 4638, 5739, 7413, 1762,  677,\n",
       "          3862, 4295, 4291, 8024, 3959, 1266, 3636, 3727,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 3680, 4692, 1168, 6821,  763, 5650, 2347, 3131,  782,  752, 6839,\n",
       "          8013, 2399, 6768, 1092,  782, 4346, 1139, 5632, 2346, 4638, 4495, 1462,\n",
       "          8013, 2552, 1963, 1143, 1490, 8013, 3801, 3717, 3632,  679,  857, 3837,\n",
       "          2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 2101, 5317, 5317, 4164, 1894,  671, 6662,\n",
       "          6624, 1962, 8024, 2668, 2703, 2128, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8024, 5739, 7413, 4266, 3678,\n",
       "           679, 6206, 1922, 7410, 6814,  749, 8024,  872, 1036, 2094, 3221, 3297,\n",
       "          3472, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 4268, 4268, 1968, 1968, 7270, 4638, 2523, 1962, 4692, 8024, 2552,\n",
       "          7000,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 2128, 2622, 8024, 3856, 3698, 7270, 2100,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101,  686, 7313, 2600, 3300,  671, 5408, 6821, 3416, 4638, 5739, 7413,\n",
       "          8024, 2127, 2844,  782, 7313, 4638, 2128, 2123, 8024, 4295, 4291, 5632,\n",
       "          2346, 8024, 5739, 7413,  679, 6421, 6158, 2563, 6381, 8024, 3719, 6823,\n",
       "          6963, 1762,  782,  812, 4638, 2552, 7027,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 4692,  671, 3613, 1526,  671, 3613,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 1036, 2094, 1343,  686,  749, 8024, 4692, 1168, 3187, 1221, 4638,\n",
       "          4266, 3678, 2769, 2552, 1962, 4563, 1962, 4563, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 6375, 1968, 1968, 4268, 4268, 2582,  720, 3833,  678, 1343, 1557,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 1762, 6821, 1469, 2398, 4670,  686, 8024, 4295, 4291, 3297, 1914,\n",
       "          4638, 2218, 3867, 7344, 1447,  749,  511, 3680, 3613, 1170, 4638, 6963,\n",
       "           833, 2552, 7000, 8024, 4706, 1419, 4178, 3801,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 1920,  782, 2582,  720, 6814, 1435,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 1922, 1377, 2667,  749, 1962,  779, 5739, 7413, 2769,  812, 3719,\n",
       "          6823, 1762,  782,  812, 2552,  704, 1962, 3416, 4638, 4268, 1968, 4638,\n",
       "          1962, 2111, 2094,  782,  812, 2552,  704, 4638, 1962, 1313, 6496, 1962,\n",
       "          1036, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 6821, 1767, 7481, 4692,  679,  749, 8024, 6821, 2111, 2094, 2523,\n",
       "          2358, 3698, 4638, 8024, 1377, 2667,  749, 8024, 5739, 7413, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 2101, 5317, 5317,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 2207, 5739, 7413,  671, 6656, 6624, 1962,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101,  686, 7313, 2600, 3300,  671, 5408, 6821, 3416, 4638, 5739, 7413,\n",
       "          8024, 2127, 2844,  782, 7313, 4638, 2128, 2123, 8024, 4295, 4291, 5632,\n",
       "          2346, 8024, 5739, 7413,  679, 6421, 6158, 2563, 6381,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 3867, 7344, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101,  686, 7313, 2600, 3300,  671, 5408, 6821, 3416, 4638, 5739, 7413,\n",
       "          8024, 2127, 2844,  782, 7313, 4638, 2128, 2123, 8024, 4295, 4291, 5632,\n",
       "          2346, 8024, 5739, 7413,  679, 6421, 6158, 2563, 6381, 8024, 3719, 6823,\n",
       "          6963, 1762,  782,  812, 4638, 2552, 7027,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101,  677, 3862, 3867, 7344, 4638, 5739, 7413,  671, 6662, 6624, 1962,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([ 101, 1962, 1036, 6947,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799829298762059021',\n",
       "  'input_ids': tensor([101, 137, 102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 8013, 2703, 2644, 2157,  782,  671, 4495,\n",
       "          2398, 2398, 2128, 2128, 8013,  978,  978, 2434, 2434, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 3143, 4851, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413,  812, 5636, 3143, 8013,  671, 6662, 6624, 1962,\n",
       "          8024, 7350, 2477, 7351,  867,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 4495, 4638,  836, 1920, 1762,  686,  679, 1914, 3198, 8024, 5739,\n",
       "          3209, 4522,  782, 6224,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101,  711, 5739, 7413, 4867,  872, 2157,  782, 2401, 4886, 3719, 6823,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 2703, 1921, 1828, 3766, 3300, 4125, 4135,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 2111, 2094,  812, 8024, 2703,  872,  812, 2128, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  872,  812, 3680, 3613, 1139, 6356, 4638, 3198,  952,\n",
       "           738, 6206, 2828, 5632, 2346, 4212, 7560, 1962, 8024, 3680, 3613, 1139,\n",
       "          6356, 6963, 5543, 2398, 2128, 2495, 3341, 8024, 1166,  782, 4638, 2157,\n",
       "          1743, 4197, 7028, 6206, 1377,  872,  738, 3300, 5632, 2346, 4638, 2157,\n",
       "          8024, 3131, 1221,  782, 3696, 4638, 1398, 3198,  738, 6206, 5632, 2346,\n",
       "          2128, 1059,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413, 5636, 3143, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101,  711, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 4638, 5739, 7413,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 4164, 1894,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101,  711, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799592761499700494',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799819319317400845',\n",
       "  'input_ids': tensor([ 101, 2552, 4563, 4638, 3187, 3791, 1461, 1429,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6799819319317400845',\n",
       "  'input_ids': tensor([ 101,  872, 2218, 6432, 1166,  782, 4295, 4291,  872, 5632, 2346, 8024,\n",
       "           872, 4638, 4269, 1968,  677, 6814, 1962,  782, 6963,  833,  677, 1921,\n",
       "          1828,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 4638, 3678,  779, 6435, 5688, 1500,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 6820, 7481, 3300, 4928, 3698, 8024, 5739, 7413, 2347, 1922, 1914,\n",
       "          8024,  800,  812, 4638, 1968, 1968, 2582,  720, 3833, 1435, 8013, 8013,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101,  679, 4761,  679, 6230, 3837, 3801,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 1372, 5543, 1762, 6821, 7027, 6843, 5739, 7413,  671, 4923,  749,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 6843, 5739, 7413,  671, 4923,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 4692,  679,  749, 6821, 3416, 4638, 6228, 7574, 8024, 2552, 4563,\n",
       "          8013, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 3056, 2552, 6162, 5511, 4638, 4563, 8024, 3801, 1944, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 2552, 7000,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 2111, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 2552, 4578, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xtzy3by3ktdzky',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094,  872,  671, 6662, 6624, 1962,  711,  782, 3696,\n",
       "          1164,  721, 4346, 1139,  749, 2399, 6768, 4495, 1462,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4635, 1355, 6843, 7946, 1355, 8024, 4696, 4578, 2552,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 2111, 2094, 1922, 1377, 2667,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101,  711, 3867, 7344, 2773, 1894, 4157, 6614,  671, 6662, 6624, 1962,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 1968, 1968, 1526, 4638, 1962, 2552, 4563, 8024, 2703,\n",
       "           872,  924, 7028,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 2111, 1036, 8024, 1420, 2533, 2769, 2552, 4578,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692, 2533, 2769, 6963, 2957, 4706, 3801,  749, 8024, 1036, 3221,\n",
       "          2023, 4638, 2552, 1928, 5489, 8024, 1373, 3833, 4708, 4638,  782, 2582,\n",
       "           720, 3833, 1435, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 2111, 2094, 8024,  872, 6821,  671, 1343, 6206,\n",
       "           749, 1968, 1968, 1288, 3340, 1462, 3307, 5401, 1957, 1968, 1968, 1780,\n",
       "          2487, 4157, 8024, 2111, 2094, 3719, 6823, 3833, 1762,  782,  812, 2552,\n",
       "           704,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 7370,  749, 4578, 2552, 8024, 6820, 3221, 4578, 2552, 8024, 5739,\n",
       "          7413,  812, 8024,  671, 6662, 6624, 1962, 8024,  704, 1744,  782, 3696,\n",
       "          3719, 6823,  679,  833, 2563, 6381,  872,  812,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1922, 1377, 2667,  749, 8024,  782, 2798,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094,  704, 1744, 1092,  782, 4638, 3528, 3416,  671,\n",
       "          6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1403, 1092,  782, 5636, 3143,  511,  671, 6662, 6624, 1962, 8024,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 2208, 2399, 2101, 5317, 5317, 8024, 4125, 3862,  704, 3719, 4495,\n",
       "          8013, 6375,  872, 2769, 2552, 4563, 8024, 6375,  872, 2769, 5862, 3801,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692, 2533, 2769, 6963, 2552, 4810,  749, 1036, 2094, 3221, 2023,\n",
       "          4638, 2552, 1928, 5489,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692, 1400, 2552, 7000, 8024, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 2015, 8024,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 3867, 7344, 5739, 7413, 2101, 3821, 3821,  511, 3719,\n",
       "          6823, 2577, 2573, 7208, 6381, 5739, 7413,  511, 2703,  872, 1762, 6823,\n",
       "          3175, 2128, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 6821,  671, 2391, 8024, 2552, 6963, 1117,  749, 8024,\n",
       "          1377, 4263, 4638, 2111, 2094, 4346, 1139, 5632, 2347, 4638, 7471, 3217,\n",
       "          8024, 4867,  872,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 4692,  749, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 2552, 1962, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101,  711, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101,  137, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 2111, 2094, 8024, 2552, 4563, 1435, 8024,  671,\n",
       "          6662, 6624, 1962,  137,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7006966963960286477',\n",
       "  'input_ids': tensor([ 101,  137, 4692,  749, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 6821,  720, 2399, 6768, 8024, 2552, 4563, 1557, 8013, 5739, 7413,\n",
       "          6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101,  830,  782, 4706,  704, 4638, 2773, 1894, 8024, 4266, 3678, 4638,\n",
       "          2111, 2094, 8013, 2703,  872,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 8024,  872, 6789, 5736,  749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 6821,  720, 2399, 6768, 4638, 1070, 2140, 6624,  749,\n",
       "          8024, 4696, 4638, 1962, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 2399, 6768, 4638, 4495, 1462, 8024, 1008,  872, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 2207, 2358, 1520, 6821, 3416, 2218, 6624,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 6375, 4268, 1968, 1468, 3833, 1435,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([101, 679, 102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 8013,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 6614,  679,  678, 1343, 1557, 8024, 1728,  711,  679, 5650, 8024,\n",
       "          1372, 5543, 3143, 4851,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7009810928149548318',\n",
       "  'input_ids': tensor([ 101, 1511, 8024, 1587, 2521,  800, 4638,  779,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 1435, 8013, 1968, 1968, 4638, 2552, 3300, 1914, 4578,\n",
       "          8024, 1762, 1921, 1828, 6206,  924,  859, 4268, 1968, 8024,  678, 6777,\n",
       "          2094,  679,  976, 5739, 7413, 8024,  976, 4268, 1968, 4638, 1962, 1036,\n",
       "          2094, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 1968, 1968, 2552, 6963, 4810,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 1968, 1968, 1526, 4638, 3056, 2552, 6162, 5511, 8024,\n",
       "          1962, 1377, 2589,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 3221,  702, 2111, 2094, 8024, 1962, 2552, 4578, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2769, 4692, 6821,  702, 6228, 7574, 4706, 3801,  671, 4684, 1762,\n",
       "           100, 2769, 4638, 2552, 6963, 6206, 4810,  749, 5739, 7413, 4268, 1968,\n",
       "          2582,  720, 3833, 1435, 2552, 4563, 3647,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 2361, 3307, 1921, 1828, 7027,\n",
       "          3766, 3300,  752, 3125, 8024, 6814, 4638, 2458, 2552, 3341, 4495, 1372,\n",
       "           976, 4268, 4268, 1968, 1968, 4638, 1962, 1036, 2094, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2552, 4578, 3647,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 6624, 1962, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([ 101, 2552, 4578,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7029948498762157342',\n",
       "  'input_ids': tensor([101, 137, 102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413, 8024,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4578, 1557, 8024, 2111, 2094,  671, 6662, 6624, 1962,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4563, 8024, 3801, 1944,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 6624, 1962, 8024, 2208, 2399, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 4578, 2515, 2552, 2796, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 2552, 3300, 1914, 4578, 1435, 8013,  976, 3678,  779, 4638,  511,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101,  679, 2361, 3307, 6821, 3416, 6371, 6399,  872,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 4266, 3678, 6421, 3300, 1914, 2552, 4578, 8024, 6821,  720, 2399,\n",
       "          6768, 4638, 2207, 5739, 7413, 8024,  671, 6662, 6624, 1962,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 8024, 1962, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 2552, 4578, 1435,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 4266, 3678, 1962, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7004371861605764365',\n",
       "  'input_ids': tensor([ 101,  976,  711,  671,  855, 3678,  779, 8024, 4692, 4708,  839, 2552,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094, 8024, 4862, 1744,  679,  833, 2563, 6381,  872,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 4578, 2552, 6821,  720, 2358, 3698, 4638, 2207,  832, 2094,\n",
       "          4696, 4638, 6375,  782, 7410,  809, 2970, 1358,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 4692, 1168, 6821,  720, 2399, 6768, 2218, 1359, 2768,\n",
       "           749,  782,  812,  679, 2682, 4692, 1168, 4638, 5739, 7413, 8024, 7370,\n",
       "           749, 2552, 4563, 2218, 3221, 3801, 1944,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094, 8024,  782, 3696, 3719, 6823, 6381, 2533,  872,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 8024,  872, 3719, 6823, 3833, 1762,  782,  812, 2552,\n",
       "           704, 8024,  711,  872, 7734, 1000,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 6624, 1962, 2111, 2094, 8013, 2703, 1921, 1828, 2401, 4886, 2571,\n",
       "           727, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 8024,  671, 6662, 6624, 1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094, 2644, 3221,  704, 1744,  782, 3696, 4638, 7734,\n",
       "          1000, 8013, 4867, 2644, 1921, 4638, 6929,  671, 6804,  671, 1147, 2128,\n",
       "          1962, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1922, 2207,  749, 8024, 1348, 1927, 1343,  671,  702, 1962, 2157,\n",
       "          2431, 8024, 3766, 1215, 3791, 2998, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094, 8024,  782, 3696, 3719, 6823,  679,  833, 2563,\n",
       "          5279,  872,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094,  671, 6662, 6624, 1962, 2703, 1921, 1828, 2128,\n",
       "          1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5636, 3143, 3867, 7344, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 2399, 6768, 4638, 5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 1962, 2552, 4578, 1557, 8024, 6929,  720, 2399, 6768,\n",
       "          1343,  671,  702,  686, 4518, 3766, 3300, 4125, 4135,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1962, 2111, 2094, 8024, 1403,  872, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 5739, 7413,  671, 6662, 6624, 1962, 8024,  782, 3696, 3719, 6823,\n",
       "           679,  833, 2563, 6381, 5739, 7413,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6989830805723811076',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1922, 2399, 6768,  749, 8024, 2552, 4563, 2703, 1762, 1921, 1828,\n",
       "          1962, 1962, 4212, 7560, 5632, 2346,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 3680, 3613, 4692, 1168, 6821, 4905, 4514, 7481, 8024, 6963,  833,\n",
       "          3801, 3837, 4007, 7481,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 6820, 3221,  702, 2111, 2094, 1557, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 2552, 4563, 1557, 2552, 7000, 3221, 4638, 8024, 6820, 3221,  702,\n",
       "          2111, 2094,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1377, 2667,  749, 8024, 2399, 2208, 4638, 5739, 7413, 8024, 4692,\n",
       "          4708,  800, 4266, 3678, 2552, 4578, 8024, 2769,  738, 3801, 3837, 4007,\n",
       "          7481,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 4266, 3678,  779,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101,  679, 5543, 4692, 6821, 4905, 1767, 7481, 8024, 6375,  782, 2552,\n",
       "          4578, 3647,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4578, 1521, 6821,  720, 2399, 6768,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 6206, 1968, 1968, 4638, 1462, 1557, 8024, 2769, 4638, 1921, 1443,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 3801, 3837,  679, 3632, 8024, 3187, 6241, 4638, 7410, 6814, 8024,\n",
       "          2703,  782,  782, 2398, 2128, 3187, 4135, 3187, 7410,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101,  679, 5543, 4692, 6821, 1767, 7481, 2552, 6963, 4563, 8024, 1922,\n",
       "          1377, 2667,  749, 8024, 1373, 4266, 3678, 1468, 6814, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101,  831, 4899, 4638, 4266, 3678, 2218, 3300,  831, 4899, 4638, 2094,\n",
       "          1957,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1191, 2552,  722, 4578, 8024,  677, 5721, 2418, 6421, 5314, 6821,\n",
       "           763, 2111, 2094, 4495, 4638, 3322,  833,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 2157,  782, 4696, 4638, 2309, 3971,  749, 8024, 8131, 2259, 8024,\n",
       "          5739, 7413,  671, 6662, 6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1403, 5739, 7413, 5636, 3143, 8024, 2703, 5739, 7413,  671, 6662,\n",
       "          6624, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 5739, 7413, 1968, 1968, 6435, 2644,  924, 7028, 6716,  860, 1557,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 2552, 4563, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 2140, 6564, 1435, 8013, 2582,  720, 5543, 4501,  678, 4266, 3678,\n",
       "          8024,  800,  812, 2582,  720, 6814, 1435, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4578, 8024, 6821,  720, 2399, 6768, 8013, 4268, 1968,\n",
       "          2582,  720, 3833, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101,  800, 4638, 4266, 3678,  791, 1400, 1468, 6814,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1962, 2552, 4563,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6976452250612944139',\n",
       "  'input_ids': tensor([ 101, 1377, 2589, 4638, 2015,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6946922230706097408',\n",
       "  'input_ids': tensor([ 101, 1567, 3198,  952, 4638,  752, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 3766, 1777, 6814, 7607, 3322, 4638, 3300, 3766, 3300,  138, 1438,\n",
       "           857,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 6432, 2141, 6413, 8024, 6820, 3221, 1744, 1079, 1962,  511, 2769,\n",
       "          1525, 7027, 6963,  679, 2682, 1343, 8024, 2218, 3221, 1762,  704, 1744,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 1921, 4135,  782, 4877, 3187, 3791, 6912, 1048, 8024, 6860, 5442,\n",
       "          2128, 2622, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622, 8024, 3341, 4495, 6820,  976,  704,\n",
       "          1744,  782,  138, 4263, 2552,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2682, 2682, 2496, 3198, 6929,  763,  782, 1762, 1785, 3322, 6929,\n",
       "           671, 1174, 8024, 6929,  763,  782, 3221, 1914,  720, 4638, 5318, 3307,\n",
       "          1469, 2607, 2672, 8024, 2682, 4263, 4638,  782, 6820, 3766, 3341, 2533,\n",
       "          1350, 4263, 8024, 2682, 2190, 5632, 2346, 4638,  779,  782, 6432, 4638,\n",
       "          6413, 6820, 3766, 3341, 2533, 1350, 6432, 8024, 1536, 8024, 6860, 5442,\n",
       "          2128, 2622,  138, 4382, 4456,  140,  138, 4382, 4456,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101,  852, 2703, 1961, 3341,  677, 1962, 1962, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622, 8024, 1962, 1962, 4397, 2667, 6716,\n",
       "          6804,  782, 8024, 2692, 1912, 1469, 3209, 1921, 6443,  738,  679, 4761,\n",
       "          6887, 1525,  702,  833, 1044, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 7556, 7599,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101,  671, 6662, 7556, 7599,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 3766, 1777, 6814, 7607, 3322, 8024,  738,  679, 2682, 1777, 8024,\n",
       "          2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 1921, 4135,  782, 4877, 3187, 3791, 6912, 1048, 8024, 6860, 5442,\n",
       "          2128, 2622, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 6860, 5442, 2128, 2622, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2600, 1762, 3777, 6804, 6624, 3766, 3300,  679, 3969, 7490, 4638,\n",
       "          8024, 3136, 6378, 3918, 1174, 8024, 2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 6860, 5442, 2128, 2622,  100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622,  138, 4263, 2552,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([101, 924, 859, 872, 812, 102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 2703, 6860, 5442, 2128, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6885912598605237507',\n",
       "  'input_ids': tensor([ 101, 6624, 1962, 8024, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6963127737955470633',\n",
       "  'input_ids': tensor([ 101, 1453, 3314, 2690, 2571,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 1963, 3362,  686, 7313, 1377,  809, 1160, 7370,  671,  816,  752,\n",
       "          8024, 2769, 1372, 2682, 2828, 4565, 4567, 4135, 7410, 1160, 7370, 8024,\n",
       "          6375,  686, 7313, 1086, 3187, 4567, 4578, 1469, 4135, 7410,  100, 8024,\n",
       "          2703, 3680,  702,  782, 6963, 3187, 4578, 3187, 4135,  511, 6375, 2769,\n",
       "           812, 3680,  702,  782, 6963,  978,  978, 2434, 2434, 2571, 2571,  727,\n",
       "           727, 2398, 2398, 2128, 2128, 4638, 6814, 1962, 3680,  671, 1921,  511,\n",
       "           100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 3300,  704, 1744,  733, 2145, 1408, 8043, 2361, 3307, 2398, 2128,\n",
       "          1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 1398,  857, 1765, 4413, 3333, 8024, 2703, 2792, 3300,  782, 2398,\n",
       "          2128,  671, 1147, 2128, 1962,  138, 4857, 4876,  140,  138, 4263, 2552,\n",
       "           140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 3307, 2792, 3300,  782, 4639, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  924,  859,  100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 4857, 4876,  800,  812, 2398, 2128, 2495, 3341, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 1927, 5468, 5442, 2398, 2128, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 1059, 3322,  782, 1447, 2398, 2128, 1726, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  138, 4382, 4456,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 6963, 2398, 2128, 1726, 2157, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 3777, 1266, 1217, 3779, 8013,  704, 1744, 1217, 3779,  100, 2703,\n",
       "           686, 4518, 2398, 2128, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 3300,  704, 1744,  733, 2145, 1408, 8043, 2361, 3307, 2398, 2128,\n",
       "          1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  686,  782, 6963, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128, 1726, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128, 2218, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 5543, 2398, 2128, 1726, 3341,  138, 4263,\n",
       "          2552,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 3143, 4519, 5632, 4197, 2203, 7028, 5632, 4197,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  800,  812, 2398, 2128, 2495, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 6821, 1377, 5543, 3221, 1369,  671,  816,  752, 4638, 2458, 1928,\n",
       "           511, 3221, 7439, 3221, 5018,  671, 3635,  511,  678,  671,  816,  752,\n",
       "          6825, 2970, 4638, 1377, 5543, 3300, 5018,  753, 3635,  138, 4125,  140,\n",
       "           138, 4125,  140,  138, 4125,  140,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  800,  812, 2398, 2128, 1915, 2495, 1726,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2792, 3300,  782, 2398, 2128, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 1962,  782,  671, 4495, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  686, 4518, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2398, 8038, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  138, 4857, 4876,  140,  138, 4857, 4876,  140,  138, 4857, 4876,\n",
       "           140, 2361, 3307,  872,  812,  671, 1147, 2128, 1962,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2398, 2128, 2495, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  733, 2145, 2398, 2128, 8024,  686, 4518, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  119,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703,  733, 2145, 2398, 2128, 8024,  686, 4518, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 3300,  671,  763, 2398, 2128, 3187,  752,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 1086, 3187, 4135, 7410,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  138, 4857, 4876,  140,  138, 4857, 4876,  140,  138, 4857, 4876,\n",
       "           140, 2703, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 6963, 2398, 2128, 1726, 2157, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 4867, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 6963, 2398, 2128, 1726, 2157, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  671, 2137, 6206, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128, 3187,  752,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2703, 2398, 2398, 2128, 2128, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 4867, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2398, 2128, 2128,  978,  978, 2434, 2434, 2571, 2571,  727,\n",
       "           727, 4638, 6814,  138, 6614,  140,  138, 6614,  140,  138, 6614,  140,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 6963, 2398, 2128, 1726, 2157, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  924, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 3766, 3300,  704, 1744,  782, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 5543, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128, 3187,  752,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  852, 2703, 3766, 3300,  704, 1744,  782,  138, 4263, 2552,  140,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([  101,   150,  8175, 13121,  6820,  3766,  2823,  1168,  1450,  1348,\n",
       "            671,   702,  1927,  5468,  4638,  8024,  2703,  2398,  2128,  2495,\n",
       "           3341,   100,   102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  671, 2137, 6206, 2398, 2398, 2128, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 6963, 2398, 2128, 1726, 2157, 2157, 7027,\n",
       "           782, 2523, 2857, 2552,  138, 4263, 2552,  140,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307,  800,  812, 5543, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 6006, 4197, 4761, 6887, 2361, 3307, 3953, 5755,  511,  852, 3221,\n",
       "           738, 2361, 3307, 5543, 1916, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128, 1726, 2157,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101,  924,  859,  924,  859,  924,  859,  924,  859, 2398, 2128, 2398,\n",
       "          2128, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7049184364088823053',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 2458, 3749, 6756, 4638, 3221, 1776, 6028,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 2533, 1226,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 6756,  711, 1567,  679, 6624, 6375, 6756, 2797, 7553,\n",
       "           677, 1343, 1557, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 3035, 4638, 1962, 8024, 1762, 2157, 1962, 1962, 4638, 1416, 8013,\n",
       "           872, 7478, 2533, 3146,  702, 5632, 6121, 6756, 6612,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 6928, 1378,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 6756, 4638, 1400, 3440,  738,  679, 6121, 1557,  671, 4821, 2218,\n",
       "          4810,  749, 2384, 2094, 3339, 3339, 4017,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 6237, 6432, 3766, 6656,  677, 1305,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 2157,  832, 3221, 4717, 6230, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6886430430208298255',\n",
       "  'input_ids': tensor([ 101,  872, 1059, 6569,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 1139, 1399,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6651, 4638, 2571, 2218, 2697, 3381,  679,  677,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 2813, 1399, 1724, 3862,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6821, 2823,  782, 3126, 4372,  679, 6121, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 4385, 1762, 2347, 5307, 3221,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 5661, 4408, 3300, 2141, 1399,  928, 2622, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6651,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([101, 671, 102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 1506, 1506,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([  101, 11186,   102]),\n",
       "  'attention_mask': tensor([1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 1440, 4638,  800,  967, 2157, 5782,  772, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 2792,  809, 2769,  812, 1744, 2157, 1215, 1744, 7354, 6612,  752,\n",
       "          3198, 4638, 1741, 2913, 2128,  924, 6820, 3221, 7478, 2382, 1962, 4638,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6820, 2682, 6651,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6651, 4638, 6820, 4696, 2571,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 2682, 1139, 1399, 1408, 8043, 8013,  872, 1963, 2703,  809,  985,\n",
       "           749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 1569, 1569, 1569,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 6651, 4638, 4696, 2571, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 1728,  711, 6821,  702, 1957, 4638, 1927, 1343, 3683,\n",
       "          6612, 6598, 3419, 1358,  839, 4638,  782, 1008,  800, 6206, 3724, 6608,\n",
       "          3621,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6915359540363939080',\n",
       "  'input_ids': tensor([ 101, 2471, 6629,  712, 1215, 3175, 2487, 4164,  679, 4007, 8043, 7410,\n",
       "          6887,  712, 1215, 3175, 3766, 3300,  671, 4157, 2637, 2640, 8043, 3766,\n",
       "          4157, 6569,  818, 8043,  671,  702, 3683, 6612, 1139, 4385, 6821, 4905,\n",
       "          7028, 1920,  752, 3125, 8024, 7674, 1044, 2418, 6421, 3466, 6374, 5632,\n",
       "          2346,  679, 3221, 1408, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101,  782, 2157, 1762, 2894, 1462, 4638, 6651, 8024, 3749, 6756, 4696,\n",
       "          4809,  752,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 3749, 6756, 2582,  720,  833, 1762, 1525,  977,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 7028, 4157, 3221, 1928, 4666, 4696, 4801, 2913, 7599, 4390, 4461,\n",
       "          6963, 4810,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 9160, 6928, 1378, 1744, 7354, 5632, 6121, 6756, 6612,  511,  511,\n",
       "           511,  511,  511,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 2553, 7557,  698, 5484, 1905, 4415,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 3766,  752,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 1506, 1506, 1506,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6804705458432003328',\n",
       "  'input_ids': tensor([ 101, 2900, 2137, 3221, 3749, 6756, 3766, 3300, 3779,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 5050, 4306, 5389, 1416, 3125, 2692,  839, 2154, 5389,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 2769, 1468, 6230, 2533, 1008, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 4821, 1168,  715, 3566, 2388, 4638,  782, 4638, 2797,  749, 8024,\n",
       "          7349, 1213, 1359, 1920, 8024, 3035,  948,  749,  511, 2769, 4638, 1921,\n",
       "          8013, 5018,  671,  702,  948, 4638,  782, 2697, 6230, 2418, 6421,  839,\n",
       "          4638, 2523, 7028, 8024, 1400, 7481, 1962, 1126,  702,  782, 2697, 6230,\n",
       "          6963,  948, 1762,  800, 6716,  677, 8024, 1068, 7241,  800, 4638, 1928,\n",
       "          2400,  679, 3221,  948, 1762,  749, 6662, 6804,  671,  904, 8013, 6821,\n",
       "           702,  715, 3566, 2388, 4638,  782, 1922, 2154,  782,  749, 8024, 6006,\n",
       "          4197, 3187, 2552, 8024,  852, 3221, 4696, 4638, 6814, 1146, 8013, 8013,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1957,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1728,  711, 6821,  702, 6225,  830, 8024, 6821,  720, 1914,  782,\n",
       "          6963, 1358,  839,  749, 8024, 6821,  752,  679, 1962, 1905, 4415,  749,\n",
       "           511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 3209, 3209, 2218, 3221, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 3125, 2692, 4638,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 2769, 2697, 6230, 3221, 3125, 2692, 4638,  798, 5301, 4692,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1505, 1853, 8024, 1400, 7481,  671, 1920, 4275, 3035,  948,  749,\n",
       "          8024, 1922, 1377, 2667,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6656, 7716, 6662, 1920, 4267,  812,  671, 3416, 3341, 1343, 5632,\n",
       "          2769,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1157, 1139, 1355, 6929,  720, 2714, 6862, 2428, 5291, 4649,  738,\n",
       "          3766, 1914, 1920, 7349, 1213, 6371, 4696, 4692,  671,  678, 6929,  702,\n",
       "           782, 3221, 4500, 2797, 2913, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 2769, 2682, 4761, 6887, 6929,  702,  782, 6820, 3833, 4708, 1408,\n",
       "          8024, 3766, 3300, 1355, 4495, 2692, 1912, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 6225,  830, 3221, 3125, 2692, 1403,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6432,  715, 3566, 2388, 6929,  702, 3187, 2692, 4638, 4696, 3018,\n",
       "          5010,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6929,  702,  782, 1762, 2864, 4212, 4275,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6821,  702, 1957, 4638,  671, 2137, 3221, 1309, 2419,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1961, 3221, 5010, 4708, 2190, 2190, 7481, 4638,  671,  702,  782,\n",
       "          5010, 1962, 1008, 3221, 6206, 2864, 4212,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 2418, 6421, 3221, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 3125, 2692, 4638, 1416, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6814, 1146, 8013, 8013, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 7942, 7339, 2753, 6873,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 3125, 2692, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 6821, 3221,  702, 1309, 2419, 1416,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '7028615037652618500',\n",
       "  'input_ids': tensor([ 101, 1457, 1957,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 6631, 6862, 6841, 2227, 5632, 6121, 6756, 1059, 6569,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 3749, 6756, 2458, 4638, 1922, 2714,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 6817, 1220, 1447, 1922, 1920, 2692, 8024, 5299, 1999,  833, 1922,\n",
       "          3136, 3340, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101,  924, 7397, 6756, 2582,  720, 1726,  752, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 3297,  711, 1726, 4638,  782, 1922, 2345, 8024, 3683, 6612, 2582,\n",
       "           812, 5543, 1327, 6756,  511, 1922, 7444, 6206, 1920, 6612, 5307, 7741,\n",
       "           749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 4696, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 2582,  720, 1726,  752, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 8114,  674, 3058, 3766, 1568, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101,  679, 3221, 6432, 5632, 6121, 6756, 5543, 2828, 3749, 6756, 3058,\n",
       "          2845, 2426, 1408, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xgfgk5d4pn3j8k',\n",
       "  'input_ids': tensor([ 101, 2769, 6230, 2533, 2418, 6421, 3221, 2682, 6375,  924, 7397, 6756,\n",
       "          2376,  800, 4788, 7599, 8024, 1377, 2667, 3766, 2682, 1168, 1385, 3322,\n",
       "           833, 6678, 1172, 6756,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1])},\n",
       " {'index': '6666314921619295496',\n",
       "  'input_ids': tensor([ 101, 3300, 6612,  752, 6662, 6804, 2218,  679, 5543,  977, 6756,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6666314921619295496',\n",
       "  'input_ids': tensor([ 101, 6756, 4390, 4461,  671, 4692, 2218,  679, 3221, 1744, 1169, 6863,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6666314921619295496',\n",
       "  'input_ids': tensor([ 101, 2458, 6887, 6756, 1059, 6569,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6666314921619295496',\n",
       "  'input_ids': tensor([ 101, 6841, 2227,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6666314921619295496',\n",
       "  'input_ids': tensor([ 101, 6821, 9908, 3221, 1146, 4868,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xac2wqftvihbu2',\n",
       "  'input_ids': tensor([ 101, 1962,  782,  671, 4495, 2398, 2128, 8024, 6821, 3416, 2190, 4852,\n",
       "           833, 6566, 6569, 4638, 3119, 6589, 1447, 2418, 6421, 2990, 1285,  711,\n",
       "          3119, 6589, 4991, 4638, 7566, 2193,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x7269wyyimyzm4',\n",
       "  'input_ids': tensor([ 101, 6821, 6206, 4895, 1278, 7368, 2533, 3300, 1914, 6818,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x7269wyyimyzm4',\n",
       "  'input_ids': tensor([ 101, 2111, 2094, 5564, 7372, 8024, 1922, 3472,  749, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x7269wyyimyzm4',\n",
       "  'input_ids': tensor([ 101, 4157, 6614, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x7269wyyimyzm4',\n",
       "  'input_ids': tensor([ 101, 2864, 1139, 3341,  679, 6121, 1408, 8043, 6820,  976, 2797, 3318,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  671,  702, 1278, 4495,  738, 3766, 3300,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711, 2769,  812,  782, 3696, 6356, 2175, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711,  769, 6356, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1765, 1277, 1278, 7368, 2218, 6432,  676, 4157,  100,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1962, 3416, 4638, 8024,  711,  769, 6356, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 4495, 1462, 4638, 2127, 2844, 5442,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  704, 1744, 5125, 4868,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711,  769, 6356, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 3862, 1990, 4989, 1046, 2593, 3131, 3791,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 2769, 3219, 3241, 6878, 1168,  749,  671, 3416, 4638, 7309, 7579,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711,  782, 3696, 2094, 2475, 1070, 5636, 3143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1044, 2141, 3177, 3862, 1990, 4989, 1046, 3791, 1557, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 2769, 2682, 6432, 8024, 8024, 8024, 8024, 8024, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  782, 3696, 4638, 1962, 6356, 2175, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1278, 7368,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1962, 3416, 4638,  711,  769, 6356, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 6356, 2175, 1398, 2562, 6789, 5736,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711,  782, 3696, 6356, 2175, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 4692, 6397, 6389,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 5314,  782, 3696, 6356, 2175, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  711,  769, 6356, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101,  137,  137, 6789, 5736,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xte5yssxwrciwm',\n",
       "  'input_ids': tensor([ 101, 1962, 3416, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  711, 3119, 6589, 1447, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  707, 1314,  679, 2707, 8024, 1235,  754, 2857, 2496, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 1914,  720, 5401, 1962, 4638, 4514, 7481, 8024, 2339,  868,  782,\n",
       "          1447,  782, 2658, 1265, 1905, 4415, 8024,  809, 1350, 2496,  752,  782,\n",
       "          2697, 2617, 6133,  677, 6858, 6121, 6589, 8024,  872, 4415, 6237, 2769,\n",
       "          2769, 4415, 6237,  872,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  711,  800, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 6756,  712,  738, 3221, 1962, 3416, 4638, 8013,  966, 4408,  782,\n",
       "          1447, 3291, 3472,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 3255, 1235, 1352, 1059,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  704, 1744, 6820, 3221, 1962,  782, 1914, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  711, 6821,  855, 1962, 2552,  782, 4157, 6614, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 1962, 3416, 4638, 1040, 2475,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 2552, 2419, 1587, 5679, 3119, 6589, 1447,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 6878, 1168, 1962, 2552, 4638, 3119, 6589,  782, 1447, 6963, 3221,\n",
       "          1962,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101,  137, 6820, 3221, 1962,  782, 1914,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 1962,  782,  671, 4495, 2398, 2128,  711,  872, 1352, 2797, 4157,\n",
       "          6614,  131,  131,  131,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 4294, 3654, 2658, 1105, 8024, 3119, 6589, 1447, 5554, 2094, 4130,\n",
       "          3833,  511,  711,  872, 1914, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 5314, 6821,  855,  749,  679, 6629, 4638, 3119, 6589, 1447, 6760,\n",
       "          1355, 4157, 6614,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 2458, 1068,  679, 5052, 4500,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 2358, 1520,  976, 4638, 4023,  778,  966, 2533, 6134, 2813,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 1962,  782,  671, 4495, 2398, 2128,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732020059977370894',\n",
       "  'input_ids': tensor([ 101, 1962,  782,  671, 4495, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xdipwd5nde7586',\n",
       "  'input_ids': tensor([ 101, 1962,  782,  671, 4495, 2398, 2128,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xdipwd5nde7586',\n",
       "  'input_ids': tensor([ 101, 3862, 1990, 4989, 1046, 2593, 3131, 3791,  679, 5543, 1139, 3341,\n",
       "          1408, 1962, 5165, 2476, 1962, 3416, 4638,  769, 6356,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 3188, 4197, 6821,  763, 1062,  830, 1384, 1355, 2357, 2972, 6843,\n",
       "           749, 7478, 3791,  841, 6863, 4638, 1062,  830, 1305, 8024, 7370,  749,\n",
       "          6206, 4067, 3926,  722, 1905, 6820, 6206, 2199,  800,  812, 5334,  722,\n",
       "           809, 3791, 2798, 2190,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 3300, 6662, 7607, 8024,  730, 2349,  510, 2769,  738,\n",
       "          6760, 1355,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 2769, 4157, 1057, 1343,  873, 6206, 1068, 3800, 1062,  830, 1384,\n",
       "          2769, 2750, 2792,  809, 6842, 1139, 3341, 1477, 8024, 4157, 4761, 5143,\n",
       "          1323,  782, 6814,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 2401, 1962, 2769, 3766, 2897,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 5488, 2412,  784,  720, 3198,  952, 3300, 1765, 7188, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 4692, 1168, 3301, 1351, 1750, 3300,  782, 6760, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 2769, 1762, 6821, 3833,  749, 8122, 2399, 8024, 3022, 1062,  769,\n",
       "          4638, 3613, 3144, 1282, 3418, 2797, 2900, 6963, 3144, 4638, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 2769, 4500, 2207, 5101, 2797, 3322, 9298, 1216, 5543, 8024, 2769,\n",
       "          2458,  749,  776, 3823, 1078,  757, 5468,  757, 6858, 1305,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 5010, 3647, 8024, 6206,  679, 3221, 6792, 6469, 2769, 6963, 4692,\n",
       "           679, 1168, 6821,  702, 8024, 6820, 1962, 2769,  679, 1599, 3614, 4500,\n",
       "          2141,  860, 1305, 8024,  743, 2797, 6134, 2797, 3322, 6963, 6206,  743,\n",
       "          3300, 9298, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 2769, 1157, 4157, 6822, 1343, 2218, 3227, 4850, 3833, 1220, 6814,\n",
       "          3309,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6980603426870742279',\n",
       "  'input_ids': tensor([ 101, 5010, 3647, 1184, 1921, 2798, 4692, 1557, 5918, 6760, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101,  872, 2347, 6158, 4685,  779, 4685, 4263,  671, 2157,  782, 6677,\n",
       "          1139, 5408, 5464,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 2347, 5307, 1068, 7308,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 2769, 2682, 4761, 6887, 1762, 1525, 7027, 1377,  809, 1215, 1062,\n",
       "           769, 1305, 8024, 2823,  679, 1168, 1215, 4638, 1765, 3175,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 2769, 3219, 1921, 6820, 6760, 1355,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 3198,  679, 3198, 2218,  833, 3300,  671, 3613, 6843,  511,  679,\n",
       "          3221, 5018,  671, 3613,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 2831, 6863,  969,  782,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 3680, 2399, 6963, 3018,  671, 3613,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 4692, 4692,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6979087409996664071',\n",
       "  'input_ids': tensor([ 101, 2769, 4692, 1168, 2769, 3301, 1351, 1750, 7027, 7481, 3300,  782,\n",
       "          6760, 1355, 8024, 2769, 2345, 4157, 2218,  928,  749,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101, 2769, 3766, 6760, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101, 2769,  128, 2399, 1184, 6158, 7745, 6814, 2792,  809, 2769,  794,\n",
       "           679, 6576, 3864, 2207,  912, 2139, 3300, 7346, 2512,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101, 1921,  677,  679,  833, 2957, 7666, 7660, 4638, 8024, 2769,  794,\n",
       "          3341, 6963,  679,  928, 6821,  763, 8024,  738,  679, 6206, 6576, 2207,\n",
       "           912, 2139,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101, 1168, 2419, 3221, 4696, 4638,  969, 4638, 8024, 2769, 3301, 1351,\n",
       "          1750,  738, 1962, 1914,  782, 1355, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101, 1921, 1557, 2769, 1343, 2399, 2218, 4692, 6814, 6821,  702,  969,\n",
       "          3867, 2622,  749, 8024,  791, 2399, 2582,  720, 6820, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731998623359339784',\n",
       "  'input_ids': tensor([ 101,  679, 7231,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '6978679609512529159',\n",
       "  'input_ids': tensor([ 101, 3301, 1351, 1750, 6821,  697, 1921, 1170, 4255,  749, 8024,  679,\n",
       "          4761, 6887, 3221, 4696, 3221,  969,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 7410, 2597,  791, 1921,  702,  702, 1762, 3301, 1351, 1750, 6432,\n",
       "          2347, 4509, 6435,  749, 8024, 2769, 3766, 3300, 4692, 1079, 2159,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101,  671, 1920, 3193, 6629, 3341, 4692, 6963, 3221, 6760, 1355, 3301,\n",
       "          1351, 1750, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 1511,  119,  119,  119,  119,  119,  119,  119,  119,  119, 1157,\n",
       "           677,  749,  671, 2496,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 3193,  677, 6629, 3341, 4692, 6224, 3301, 1351, 1750, 2523, 1914,\n",
       "          1355, 8024, 2218, 4157, 6822, 1343, 4692, 8024,  852, 2769,  679, 1355,\n",
       "          3301, 1351, 1750,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 6821, 4905, 2769, 4692, 6963,  679,  833, 4692,  671, 4706,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101,  671, 5663,  677, 2496, 4638, 1059, 3221, 1957, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101,  679, 3221, 1416, 8024, 6963, 4500, 2207, 4923, 2415, 2853, 1946,\n",
       "           749, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 2769,  738, 3221, 8024,  671, 3018, 2130,  677, 2833, 7509, 5018,\n",
       "           671,  702, 1170, 1168, 6821,  702, 2218, 3221,  969, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 1157, 1157, 2769,  738, 2462,  749, 8024, 2462, 2130, 1355, 4385,\n",
       "          3221,  969, 4638, 8024, 3362, 3171, 1160, 7370,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 3219, 1921, 4692, 3301, 1351, 1750, 1962, 1914,  782, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 1921,  678,  679,  833, 4635, 4635, 2957, 7666, 7660,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 6821, 4905, 2769,  794, 3341,  679,  677, 2496,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 2769, 3193,  677, 2798, 1157, 1157, 3018,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 2769,  679, 1777, 1062,  769, 6756, 7744, 4708, 2769, 2552, 4263,\n",
       "          4638, 2207, 3040, 2805,  679, 7676, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101,  677, 2496, 1568,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 6821, 1126, 1921, 3301, 1351, 1750, 6963, 3221, 1355, 6821,  702,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6731971438481394958',\n",
       "  'input_ids': tensor([ 101, 1530, 8024, 1333, 3341, 3221,  969, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 3301, 1351, 1750, 1170, 2242,  749, 8024, 6963, 2812,  749, 6929,\n",
       "          2582,  720, 1215, 1450,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 6863, 2768, 4852,  833, 2512, 1510, 8024, 6206,  698, 5484, 1905,\n",
       "          4415,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 1157, 6760, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 2769, 2233, 4197,  677, 2496,  749, 8024, 3617, 1526, 3187, 3801,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 2812, 6963, 2812,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 2769,  677, 2496,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 3238, 8013, 2769, 2812,  749, 8024, 6158, 7745,  749, 8024, 2582,\n",
       "           720, 1215,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 3415, 3828, 1062,  769, 1305, 8172, 1041,  966,  784,  720, 3198,\n",
       "           952, 3118, 2898, 2128, 1294, 8111, 1492,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6732370114181598477',\n",
       "  'input_ids': tensor([ 101, 2812,  749, 8024, 1468, 1215, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 2831, 1168, 6863, 6469, 5442, 3766, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 3300, 1377, 5543, 3221, 4761, 6887, 4638,  782, 1922, 1914,  749,\n",
       "          8024, 1400, 2637,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 1048, 6589, 1377, 5543, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 1062,  769, 1305, 3315, 3341, 2218, 1048, 6589,  511, 1372, 6206,\n",
       "           872, 5632, 2346, 1041, 7178, 5445, 2347,  511, 6821, 4905,  752, 6963,\n",
       "          3300,  782,  928,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 8142, 2399, 5381,  677, 2218, 2458, 1993, 3300, 6821, 4905, 1048,\n",
       "          6589, 6843, 1062,  769, 1305, 4638,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x67v5cyrwg7ifq',\n",
       "  'input_ids': tensor([ 101, 3845, 3975, 2356, 4638, 1062,  769, 6756, 1048, 6589, 1126, 2399,\n",
       "           749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343, 8024, 3766, 7178, 3683, 4567, 3681, 1377, 2586,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101,  679, 4500, 8198,  674, 8024, 8108,  674, 2218, 1377,  809,  749,\n",
       "          8024, 1762, 1744, 1079, 6611, 8108,  674, 4638,  697, 2399, 6820, 2533,\n",
       "          1239, 5165, 6175, 5587, 2372, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 3123, 2552, 8024, 1963, 3362, 3300, 8024,  738, 6762,  679, 1168,\n",
       "          1493,  812, 6821, 2376, 4956,  782, 1343,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 1963, 3362,  679, 3221, 6469, 6241, 4638, 6413, 8024, 2769, 2682,\n",
       "          1343, 8024, 2769, 2682, 1300,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 6863, 6469, 5442,  679, 2418, 6421, 1905, 4415, 1408, 8043, 4385,\n",
       "          1762, 5381,  677, 6469, 6241, 1922, 1914, 8024, 2418, 6421,  698, 5484,\n",
       "          1905, 5385, 2798, 6121, 8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 6863, 6469, 5442, 1373,  800, 1343, 2692, 1920, 1164, 2802, 2339,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 2682, 2845, 1399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2845,  702, 1399, 8024,  784,  720, 3198,  952, 2875, 8024,  784,\n",
       "           720, 3198,  952, 1343, 8024, 3766, 1215, 3791, 1435, 8013, 4522, 1762,\n",
       "          1744, 1079, 8024, 7213, 6121, 6206, 2823, 2769, 7937, 4172,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 5276, 2769, 8024, 7390, 3198, 1139, 1355,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 3221,  679, 3221, 4696, 4638, 8024,  833,  679,  833, 3221,  969,\n",
       "           928, 2622,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 1963, 3362, 3300, 8024, 6381, 2533, 1373, 2769,  671, 1898,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101,  671,  702, 3299, 6820,  679, 1916, 3341, 1726, 3322, 4873, 1557,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 3300, 1462,  976, 3766, 1462, 4500, 5050,  749, 1438, 1762, 4862,\n",
       "          1744, 1391, 4921, 7649,  738, 6672, 2141,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1372, 2682, 4761, 6887, 1726, 3341, 3322, 4873, 3221, 1914,\n",
       "          2208, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 6469, 6241, 1557,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2582,  720, 2845, 1399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2582,  720, 2845, 1399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3x5ukaaarhwb6mk',\n",
       "  'input_ids': tensor([ 101, 2769, 1343, 2845, 1399,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 1385, 3322, 1914, 2208, 7178,  671,  702, 3299, 8024, 2769, 3341,\n",
       "          4510, 6413, 3221, 1914, 2208,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 3300, 6821,  720, 7770, 4638, 2339, 6598, 8024,  704, 1744, 1093,\n",
       "          3696, 2339, 6963, 1059, 6956, 6624, 2130,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 6821, 3416, 6863, 6469, 4495,  752, 4638,  782, 6206, 6375, 1961,\n",
       "           800, 7946, 1399, 1296,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 5468, 5143,  671,  678, 2769, 2682, 1343, 2339, 6598, 2523, 6430,\n",
       "          2663,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2361, 3307, 2831,  857, 8024, 1161, 1152, 8024, 5314,  754, 5385,\n",
       "          3621, 8024,  671,  674, 1039, 8024,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2875,  782, 4638, 6413, 2218, 6432,  671, 1898, 8024, 2769, 1343,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2769,  738, 1343,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 6206,  679, 6206, 2458, 2905, 3322, 4638, 8043,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2582,  720, 5468, 5143,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 6863, 6898,  722,  782,  671, 2137, 3221, 6400, 7745, 4306, 8024,\n",
       "          2553, 7557, 2831,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101,  698, 2674,  698, 1215,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2875, 5470,  671,  702, 2099,  744,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 6821,  679, 3221, 6863, 6469,  844, 6369, 6400, 7745,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 1962, 1914, 1762, 2833, 7509, 7027, 7745,  782, 2875, 2339,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2769, 1372, 2682, 4761, 6887, 1355, 6469, 6241, 4638, 1068, 6822,\n",
       "          1343,  749, 3766, 3300,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2769, 2544,  928, 1750, 7027,  738, 4692, 1168,  749,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2418, 6421, 2828, 6821,  702, 3141, 2357, 6469, 6241, 4638,  782,\n",
       "          2831, 6629, 3341,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 5468, 5143, 3175, 2466, 1377,  809, 1440, 4761, 1408,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 6963, 3119, 1168, 6821, 3340,  928, 2622,  749, 4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2582,  720, 1905, 4415, 6821,  702, 6469, 6241, 8013, 8013, 8013,\n",
       "           102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 8024, 6820, 6206,  679, 6206, 4184, 2339, 1408, 4522,  702, 1399,\n",
       "          7583,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 2397, 1658, 6821,  720, 6826, 2798, 4761, 6887, 6821,  763,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '3xann9z9p6a9cnk',\n",
       "  'input_ids': tensor([ 101, 3300, 6929,  720, 7770, 4638, 2339, 6598, 2769, 5507, 2137, 1343,\n",
       "          4638,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6986540295076859144',\n",
       "  'input_ids': tensor([ 101, 2823, 1168, 6821,  702, 5632, 2054,  860, 6841, 3389, 1168, 2419,\n",
       "          8013,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " {'index': '6986540295076859144',\n",
       "  'input_ids': tensor([ 101, 6469, 6241, 6963,  794, 1525, 3341, 4638, 1450, 8024, 2418, 6421,\n",
       "          3221, 1166, 3300, 4500, 2552, 4638,  782,  511,  679, 1377, 5543, 7312,\n",
       "          2533, 3187, 5464, 4638,  782, 1355, 6469, 6241,  511,  102]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1])},\n",
       " ...]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16128,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_comments = {}\n",
    "for comment in b:\n",
    "    index = comment['index']\n",
    "    if index not in grouped_comments:\n",
    "        grouped_comments[index] = []\n",
    "    grouped_comments[index].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': '3x4zj7hyemptkvm', 'merged_feature': array([ 3.31136286e-01, -5.27080297e-02, -8.61083642e-02, -3.28927953e-03,\n",
      "        5.10410130e-01,  1.73011228e-01, -2.29835033e-01,  2.82268465e-01,\n",
      "       -3.37671816e-01,  3.77170026e-01,  1.28737852e-01, -3.13593328e-01,\n",
      "        8.80487189e-02,  6.25338733e-01,  8.47829640e-01, -8.83926302e-02,\n",
      "       -4.35855798e-02,  3.46386105e-01, -2.16170311e-01,  2.12434128e-01,\n",
      "       -2.24721834e-01,  3.89261055e-03,  5.90885244e-02,  1.70138001e-01,\n",
      "        5.85317433e-01, -4.66737658e-01,  5.74524462e-01, -4.26458955e-01,\n",
      "        2.52191633e-01, -1.78976178e-01, -2.58813620e-01,  3.59810203e-01,\n",
      "        5.98238781e-02,  3.09427008e-02, -8.68773833e-02, -1.42996653e-03,\n",
      "       -8.05156350e-01,  1.03550829e-01, -5.02201676e-01, -4.95455831e-01,\n",
      "        5.07095754e-01, -3.08932811e-01, -1.82036042e-01, -3.53716850e-01,\n",
      "        1.66972518e-01,  3.01892199e-02, -2.49630526e-01, -9.71173868e-02,\n",
      "        4.30593073e-01,  4.52418596e-01,  6.47896752e-02,  9.65357780e+00,\n",
      "       -1.11661911e-01, -4.85427588e-01, -8.39508533e-01,  4.20174927e-01,\n",
      "        3.48868698e-01, -2.32603341e-01, -3.52527767e-01, -6.80436075e-01,\n",
      "       -3.81931849e-02, -6.53388873e-02, -5.64741850e-01, -6.72019571e-02,\n",
      "        3.00826319e-02,  1.10447727e-01,  2.51281023e-01, -1.58766925e-01,\n",
      "       -1.47843674e-01,  5.51702119e-02, -6.96701184e-02, -3.58535528e-01,\n",
      "       -5.42120516e-01, -2.49638152e-03,  1.31179243e-01,  3.41576159e-01,\n",
      "       -1.45494454e-02, -3.55141371e-01, -2.22724825e-01, -2.46663526e-01,\n",
      "       -7.11062193e-01, -6.87674224e-01, -5.44877350e-01,  5.47304988e-01,\n",
      "       -3.28878403e-01,  3.22277725e-01, -6.08139813e-01, -6.89093053e-01,\n",
      "        6.33111075e-02, -6.33809566e-01, -1.97600365e-01,  2.42094770e-01,\n",
      "        4.10034984e-01,  1.68733716e-01,  3.58197063e-01,  4.94611025e-01,\n",
      "       -7.46199116e-02, -8.63203406e-01,  1.14346549e-01,  5.34744337e-02,\n",
      "       -3.34252417e-01, -6.39131218e-02,  1.99421681e-02, -9.17907059e-01,\n",
      "       -2.51361758e-01, -2.78532565e-01, -2.96628892e-01, -2.98313826e-01,\n",
      "       -9.45303962e-02,  5.26042171e-02, -5.10684013e-01, -8.40304971e-01,\n",
      "       -5.49000084e-01, -1.52756825e-01, -5.46997547e-01, -4.89038527e-01,\n",
      "       -4.23130661e-01,  5.37067592e-01,  8.02532852e-01, -2.79987961e-01,\n",
      "        7.63229668e-01,  6.38081491e-01,  2.71030277e-01,  5.97821362e-02,\n",
      "        4.56797689e-01, -7.92457759e-01, -2.18997933e-02, -9.76654664e-02,\n",
      "       -5.22978485e-01, -1.07684746e-01, -2.48062089e-01,  7.60654435e-02,\n",
      "        1.11930645e+00,  4.30046730e-02,  8.42243806e-02, -4.74604785e-01,\n",
      "        2.62341559e-01, -2.51832783e-01, -3.57836008e-01,  3.09692472e-01,\n",
      "        1.62189499e-01, -6.84294924e-02, -3.79574507e-01,  8.04717124e-01,\n",
      "        1.05359212e-01, -8.34911466e-02,  6.22763097e-01, -1.85254216e-01,\n",
      "        2.95480005e-02,  4.62094247e-01,  1.15169920e-01, -7.39208341e-01,\n",
      "       -6.51172519e-01, -4.23964411e-01, -8.84732902e-01,  2.64948040e-01,\n",
      "       -1.02600485e-01, -7.57680655e-01,  1.32531837e-01, -4.68784660e-01,\n",
      "       -2.74046034e-01,  2.18884170e-01,  1.27092488e-02,  4.22974735e-01,\n",
      "        2.83826254e-02, -1.11337531e+00, -2.14823455e-01,  1.28938749e-01,\n",
      "       -4.66730654e-01,  3.23520929e-01, -3.88783664e-02,  7.79488623e-01,\n",
      "        1.19103670e-01,  4.73329455e-01, -3.46953452e-01, -1.50632288e-03,\n",
      "        2.32585240e-02, -1.73388198e-01, -3.16472590e-01, -2.11994395e-01,\n",
      "       -5.57149239e-02, -1.80092245e-01, -1.08050093e-01,  7.55793229e-02,\n",
      "        2.19762012e-01,  2.66425341e-01,  5.29824436e-01, -3.94673496e-01,\n",
      "        2.76586384e-01, -1.08902931e-01,  7.63645172e-02,  3.93155403e-02,\n",
      "       -2.91162640e-01, -2.00613424e-01,  2.80896902e-01,  8.50324333e-02,\n",
      "       -1.96470305e-01,  1.57966137e-01,  2.36211300e-01,  1.58476397e-01,\n",
      "       -1.87058032e-01, -2.33875826e-01,  7.97906145e-02,  7.77263105e-01,\n",
      "       -2.31082708e-01,  9.25902277e-02,  1.39628425e-02, -1.41340658e-01,\n",
      "       -2.03113958e-01, -8.54834914e-02, -7.77551115e-01,  3.94744068e-01,\n",
      "       -5.64991057e-01, -5.19928575e-01,  2.51747906e-01, -8.38419318e-01,\n",
      "        2.57890075e-01, -3.12805533e-01,  1.87220246e-01,  1.20182775e-01,\n",
      "        2.51347363e-01,  2.81123966e-01,  6.46891713e-01, -2.59944737e-01,\n",
      "        1.09024569e-01, -3.35726887e-01,  4.74586934e-02,  2.42411494e-01,\n",
      "        3.63203466e-01,  4.83616203e-01, -4.53283489e-02,  3.32482159e-01,\n",
      "        1.87550515e-01, -1.48431271e-01, -3.67136031e-01, -2.53784865e-01,\n",
      "        4.72963639e-02,  1.68477893e-01, -7.31301427e-01,  7.15997955e-03,\n",
      "       -1.27944484e-01, -3.63451660e-01, -2.44540811e-01,  3.60605657e-01,\n",
      "        5.69166839e-01, -9.79924202e-02,  8.61212686e-02,  7.17367351e-01,\n",
      "       -6.08422197e-02, -2.67916918e-02,  3.43132108e-01, -3.39013964e-01,\n",
      "        3.16945940e-01, -9.01480541e-02, -2.54481167e-01,  1.84272543e-01,\n",
      "       -2.04314023e-01, -5.00689566e-01,  2.95102280e-02,  1.17643982e-01,\n",
      "        2.65943438e-01,  1.64160520e-01,  1.80260450e-01,  2.11451605e-01,\n",
      "        7.33859718e-01,  2.37993062e-01,  1.48201780e-02, -1.76485017e-01,\n",
      "        5.82734406e-01,  3.34544986e-01, -3.44841555e-02, -2.45103702e-01,\n",
      "       -2.89555937e-01, -6.95470154e-01, -3.02073389e-01,  7.81984627e-02,\n",
      "        4.77363944e-01, -1.20206252e-01,  7.00497404e-02, -1.26774698e-01,\n",
      "        7.68601358e-01, -5.31156301e-01, -4.08934176e-01, -5.33237159e-01,\n",
      "       -4.50540006e-01, -4.56821769e-01, -3.09952796e-01, -8.38416293e-02,\n",
      "       -8.98202509e-02, -7.78373539e-01, -6.81552365e-02, -4.43186581e-01,\n",
      "       -7.73287863e-02,  3.04702610e-01,  9.11515653e-01,  7.05973208e-01,\n",
      "       -2.07352564e-01, -5.30688345e-01, -1.86372101e-01, -8.34986269e-01,\n",
      "       -3.73363107e-01, -2.28954628e-01, -5.81886590e-01, -3.22758034e-02,\n",
      "        2.83341527e-01, -5.83238423e-01,  3.47935967e-02, -4.66259941e-02,\n",
      "        4.69171196e-01,  2.82783747e-01, -4.67227310e-01,  7.21379668e-02,\n",
      "       -7.25752041e-02, -2.08011061e-01, -1.18596017e+00, -4.22880799e-01,\n",
      "       -2.53926426e-01,  3.39384139e-01,  5.84846810e-02,  2.46096134e-01,\n",
      "        6.51966110e-02, -2.61268765e-01,  4.94667679e-01,  5.34014761e-01,\n",
      "        3.88843030e-01, -4.21091132e-02,  3.62775147e-01,  1.58374339e-01,\n",
      "        4.73820776e-01, -7.07198083e-01, -6.53778017e-02,  3.41887802e-01,\n",
      "       -6.52057946e-01,  5.99290766e-02,  9.46908891e-02, -5.13627529e-02,\n",
      "        5.91390908e-01,  1.77619025e-01, -5.18763244e-01, -9.86062527e-01,\n",
      "        4.93365973e-01, -2.37778351e-01,  9.07437801e-01,  3.77142698e-01,\n",
      "       -7.92633414e-01,  8.00166428e-02, -5.17569832e-04, -6.96958125e-01,\n",
      "        4.16648500e-02,  4.54203546e-01, -4.52939183e-01,  4.86840785e-01,\n",
      "       -5.00202835e-01, -3.37167114e-01,  4.24694866e-01,  7.35836327e-01,\n",
      "       -1.23547144e-01, -3.73734802e-01,  7.57186636e-02,  3.48769218e-01,\n",
      "       -5.50521374e-01,  7.98032045e-01, -5.12458310e-02, -3.59068722e-01,\n",
      "        3.37313712e-01,  4.00783271e-01, -3.03641349e-01, -4.65029955e-01,\n",
      "       -2.17501298e-01, -2.55124331e-01, -2.64491022e-01,  1.22775495e-01,\n",
      "        5.47331095e-01, -6.58993959e-01, -3.74389619e-01, -4.34961170e-02,\n",
      "       -2.62766749e-01,  2.53854841e-01,  2.58148134e-01, -6.36902153e-02,\n",
      "       -6.52357757e-01,  2.21222609e-01, -1.26294985e-01,  1.09871435e+00,\n",
      "        4.86157417e-01,  2.01364562e-01, -4.23053890e-01, -5.68566620e-01,\n",
      "        1.68497682e-01, -5.16521394e-01, -6.81122959e-01,  4.83481944e-01,\n",
      "        8.63135234e-02, -2.79057354e-01,  2.75375128e-01,  1.23959315e+00,\n",
      "       -1.32956311e-01, -3.05295438e-01, -1.67226866e-01,  4.09855127e-01,\n",
      "       -5.16767979e-01, -1.93231646e-02, -8.82777348e-02, -1.36976615e-01,\n",
      "        1.91663489e-01, -7.21057892e-01, -1.84424043e-01,  2.49568939e-01,\n",
      "        4.23907340e-01, -6.08563900e-01, -3.67106140e-01,  2.85980761e-01,\n",
      "        5.66818774e-01,  9.50119793e-02, -5.43386102e-01,  1.22003749e-01,\n",
      "        1.86424688e-01, -1.32995816e-02, -4.57743496e-01, -3.68647799e-02,\n",
      "       -4.90794241e-01, -1.62455007e-01, -1.31847486e-01, -3.20202827e-01,\n",
      "        9.01718259e-01, -1.72930043e-02,  3.16844583e-01, -2.02496555e-02,\n",
      "        4.21648443e-01, -1.34720832e-01, -7.00121224e-02,  8.90947729e-02,\n",
      "       -2.36796081e-01,  2.70283282e-01,  2.40657017e-01,  6.07720494e-01,\n",
      "       -1.58160016e-01,  3.22227240e-01,  1.90985724e-01, -4.32297178e-02,\n",
      "        8.41360912e-02, -4.95148897e-01,  4.19238955e-01,  7.54213989e-01,\n",
      "        4.12470877e-01,  5.37807167e-01,  1.09125161e+00, -5.02509296e-01,\n",
      "        1.21185049e-01,  1.88762993e-02,  2.16779590e-01,  2.13396102e-02,\n",
      "       -5.63556850e-01, -1.44417554e-01,  5.00075638e-01, -7.44754314e-01,\n",
      "        6.11824334e-01,  1.18705921e-01, -1.13079853e-01,  1.49233982e-01,\n",
      "       -2.39082500e-01,  6.34145916e-01, -6.82316899e-01,  4.15418625e-01,\n",
      "       -9.71984863e-02, -7.40360439e-01, -1.08369386e+00,  5.86213395e-02,\n",
      "       -2.98426092e-01,  6.66131750e-02,  1.05464153e-01, -2.69658238e-01,\n",
      "       -1.63892601e-02,  1.28727555e-01, -3.74272794e-01,  3.62437218e-01,\n",
      "       -1.55973554e-01, -2.34656692e-01, -1.36248374e+00, -8.11248600e-01,\n",
      "       -2.65465975e-01, -3.21071953e-01,  3.44630927e-02, -3.67465079e-01,\n",
      "        8.37859735e-02, -9.35395583e-05,  2.78399915e-01, -6.33014083e-01,\n",
      "       -2.46122807e-01,  5.76167285e-01,  4.36941773e-04, -3.49961758e-01,\n",
      "        2.02621162e-01, -1.49640992e-01, -7.72543848e-02, -7.45929897e-01,\n",
      "        7.73626864e-01, -6.59468323e-02,  4.24205184e-01, -2.03285336e-01,\n",
      "        8.36673021e-01, -9.89387810e-01,  4.56903994e-01, -6.44938126e-02,\n",
      "       -3.65091890e-01,  2.03324273e-01,  2.88197130e-01, -2.12640971e-01,\n",
      "       -1.26185521e-01, -1.59175232e-01,  2.50781476e-01, -7.76075482e-01,\n",
      "        1.24840409e-01, -6.53259575e-01,  3.33699942e-01,  4.93539035e-01,\n",
      "       -3.95117342e-01, -3.32529515e-01,  1.97369844e-01, -2.20487073e-01,\n",
      "       -2.83564597e-01, -1.20306807e-02,  1.07972607e-01, -1.35238739e-02,\n",
      "        3.18427145e-01,  3.33298206e-01, -6.01324558e-01, -3.46039414e-01,\n",
      "        3.84689182e-01,  2.39737302e-01, -6.15989603e-03,  6.16105914e-01,\n",
      "        5.57707191e-01, -2.81823099e-01,  1.41150072e-01,  2.74324238e-01,\n",
      "        1.14864506e-01, -3.02503943e-01, -1.90254077e-01,  2.53862143e-03,\n",
      "       -2.20812619e-01, -2.66766638e-01, -2.99334675e-01,  2.04703674e-01,\n",
      "        1.11400625e-02, -3.02994363e-02, -9.25911516e-02,  3.43583792e-01,\n",
      "        7.18248934e-02, -2.45078340e-01, -4.86272186e-01, -4.29679185e-01,\n",
      "       -3.20449024e-01,  2.28642732e-01,  2.59832770e-01, -4.52443630e-01,\n",
      "        4.76365358e-01, -2.95144498e-01,  2.64999717e-01,  6.89305887e-02,\n",
      "       -1.19944058e-01,  2.00190321e-01, -3.73241119e-02, -3.85327488e-01,\n",
      "       -5.22882819e-01,  2.39082783e-01, -3.56485069e-01, -2.73741812e-01,\n",
      "       -1.75939485e-01,  4.15048063e-01,  4.01224345e-02, -1.06246509e-01,\n",
      "       -4.92508300e-02, -2.59484231e-01, -3.06090891e-01,  1.84883222e-01,\n",
      "        3.67214024e-01,  1.05654538e-01,  4.88318115e-01,  3.72763649e-02,\n",
      "        8.79297912e-01,  5.57705760e-01,  1.29943490e-01,  1.04335479e-01,\n",
      "       -1.24068215e-01, -2.77712137e-01,  4.57735837e-01,  5.89409590e-01,\n",
      "        1.82853594e-01, -6.12229668e-02, -5.98327816e-01,  2.50114620e-01,\n",
      "       -1.01294667e-01, -7.29693025e-02, -2.81268507e-01,  2.77138084e-01,\n",
      "       -2.36306921e-01,  3.41095299e-01,  2.80353814e-01, -5.17810404e-01,\n",
      "        7.71632969e-01, -1.06333986e-01, -4.36877877e-01,  1.91748410e-01,\n",
      "        2.61430681e-01, -2.41535053e-01, -2.98656709e-02,  2.99879670e-01,\n",
      "       -2.40680695e-01, -2.72339672e-01,  4.28308219e-01, -2.11595833e-01,\n",
      "        1.69904917e-01,  1.75685614e-01, -5.42019367e-01,  2.32074142e-01,\n",
      "        3.74326780e-02,  8.09037089e-01,  4.98183608e-01, -3.40117902e-01,\n",
      "        2.34896820e-02, -1.80783302e-01, -3.69570732e-01, -7.21626133e-02,\n",
      "        7.69654036e-01,  2.87777841e-01,  6.56810105e-01,  5.97526431e-01,\n",
      "        3.23511750e-01, -4.36222970e-01,  1.09858856e-01,  5.53869963e-01,\n",
      "       -2.08886802e-01, -3.30027312e-01,  5.11722118e-02, -3.91629636e-01,\n",
      "        9.00039002e-02,  5.74994385e-01,  4.96228218e-01,  3.84014733e-02,\n",
      "        1.84176683e-01, -2.84074306e-01, -6.71918690e-01, -5.03739953e-01,\n",
      "        3.01190048e-01, -1.13932211e-02, -9.68476459e-02, -4.08737779e-01,\n",
      "       -3.35262567e-02, -4.35106426e-01, -1.91442713e-01, -1.75174415e-01,\n",
      "       -3.56670707e-01,  1.24359271e-02, -3.09077233e-01, -2.18693644e-01,\n",
      "        2.92495966e-01, -8.20700973e-02, -4.45221364e-02, -6.03998482e-01,\n",
      "        3.12027074e-02, -5.16415894e-01, -2.24175796e-01,  1.22078247e-01,\n",
      "       -1.73237532e-01, -2.34910995e-01, -4.55778450e-01, -2.90872663e-01,\n",
      "       -8.34901258e-02,  2.55699217e-01,  1.05671859e+00, -4.76484299e-01,\n",
      "        1.97972700e-01, -4.08314437e-01, -2.15026408e-01, -4.40764666e-01,\n",
      "       -5.31330109e-01, -2.42426366e-01,  1.50571942e-01, -4.01817739e-01,\n",
      "        6.18105493e-02, -8.09219003e-01, -4.63627577e-01,  4.27678347e-01,\n",
      "       -1.50372818e-01,  2.64046758e-01, -1.81924790e-01, -6.06020510e-01,\n",
      "       -8.32070932e-02, -2.41973624e-01,  6.43276334e-01,  6.53913468e-02,\n",
      "        7.18422309e-02, -2.44217232e-01, -4.32689846e-01,  7.60984945e+00,\n",
      "        3.36567372e-01, -1.04347050e-01,  4.05141205e-01, -1.70043588e-01,\n",
      "       -4.91048753e-01, -1.35674253e-01,  3.68009090e-01, -8.46988708e-03,\n",
      "       -2.27597058e-01, -1.23586334e-01, -1.47500203e-03,  2.94897705e-01,\n",
      "       -2.02620849e-01,  2.56261081e-01,  2.72694826e-01,  1.04388759e-01,\n",
      "       -4.48490232e-01, -1.90241501e-01,  3.77695471e-01,  3.39830220e-01,\n",
      "       -1.07624972e+00, -4.69599098e-01, -3.64165366e-01,  2.26631165e-01,\n",
      "        1.75682038e-01, -1.85303807e-01, -1.36690453e-01,  5.16975783e-02,\n",
      "        2.57964462e-01, -2.28724211e-01, -7.52791882e-01,  4.25872892e-01,\n",
      "        2.66264647e-01, -8.10851336e-01,  1.66075304e-01,  4.63712513e-02,\n",
      "        2.64425755e-01,  5.85516274e-01, -1.24147281e-01,  9.54597592e-01,\n",
      "       -2.09660456e-01,  1.08169038e-02,  4.11148399e-01,  3.91016722e-01,\n",
      "        3.35232526e-01, -1.63964793e-01,  5.74063301e-01, -3.06385130e-01,\n",
      "       -9.66096967e-02, -5.14809608e-01,  2.35108167e-01, -4.06553000e-01,\n",
      "       -1.28042889e+00,  1.78388524e+00,  1.08055532e-01, -1.18466988e-01,\n",
      "       -1.98151041e-02, -6.35705769e-01, -6.79757819e-02, -1.10316582e-01,\n",
      "        3.29980612e+00, -2.81964839e-01,  1.22443497e-01, -3.58878493e-01,\n",
      "        2.60501921e-01, -1.73867479e-01, -1.70484945e-01, -1.93940565e-01,\n",
      "       -6.06101632e-01,  3.08274180e-01,  4.26367819e-01, -1.37377242e-02])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "model_name = './bert-base-chinese/'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "def calculate_attention_weights(group):\n",
    "    num_keywords = len(group)\n",
    "    return np.ones(num_keywords) / num_keywords\n",
    "\n",
    "final_features = []\n",
    "\n",
    "# 遍历分组后的数据\n",
    "for index, group in grouped_comments.items():\n",
    "    all_input_ids = []\n",
    "    all_attention_weights = []\n",
    "\n",
    "    for comment in group:\n",
    "        feature = comment['input_ids']\n",
    "        all_input_ids.append(feature)\n",
    "\n",
    "    # 计算注意力权重\n",
    "    attention_weights = calculate_attention_weights(group)\n",
    "\n",
    "    # 使用注意力权重对特征进行融合\n",
    "    merged_feature = np.average(all_input_ids, axis=0, weights=attention_weights)\n",
    "\n",
    "    # 存储最终结果\n",
    "    final_features.append({'index': index, 'merged_feature': merged_feature})\n",
    "all_merged_features = np.vstack([feature['merged_feature'] for feature in final_features])\n",
    "# 打印最终结果\n",
    "for final_feature in final_features:\n",
    "    print(final_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_feature['merged_feature']\n",
    "\n",
    "all_merged_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./bert-base-chinese/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2802\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2801\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2802\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2804\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2888\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2883\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2884\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2885\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2886\u001b[0m         )\n\u001b[1;32m   2887\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2890\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2909\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2910\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2927\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3079\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3070\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3071\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3072\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3077\u001b[0m )\n\u001b[0;32m-> 3079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils.py:801\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 801\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m    803\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    804\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "model_name = './bert-base-chinese/'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(keywords, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1991, -0.0138, -0.1109,  ...,  0.2633,  0.0440, -0.0900],\n",
      "        [ 0.1991, -0.0138, -0.1109,  ...,  0.2633,  0.0440, -0.0900],\n",
      "        [ 0.1991, -0.0138, -0.1109,  ...,  0.2633,  0.0440, -0.0900],\n",
      "        ...,\n",
      "        [-0.2289,  0.5408, -0.4242,  ..., -0.0441, -0.1671, -0.2258],\n",
      "        [-0.2289,  0.5408, -0.4242,  ..., -0.0441, -0.1671, -0.2258],\n",
      "        [-0.2289,  0.5408, -0.4242,  ..., -0.0441, -0.1671, -0.2258]])\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "features = last_hidden_states.mean(dim=1)  \n",
    "\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeatures\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = './fea/text_f.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(features, features_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(features, features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
